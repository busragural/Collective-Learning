{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "mask_filler = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-turkish-cased\", device=device)\n",
    "\n",
    "\n",
    "def augment_text_with_berturk(text, num_variations=3):\n",
    "    augmented_texts = set()  \n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        words = text.split()  \n",
    "        x = max(1, len(words))\n",
    "\n",
    "        for i in range(x):\n",
    "            masked_text = words.copy()\n",
    "            \n",
    "            mask_index = random.randint(0, len(masked_text) - 1)\n",
    "            masked_text[mask_index] = \"[MASK]\"\n",
    "            masked_sentence = \" \".join(masked_text)\n",
    "            \n",
    "            predictions = mask_filler(masked_sentence)\n",
    "            \n",
    "            if isinstance(predictions, list) and len(predictions) > 0:\n",
    "                pred = predictions[0]\n",
    "                if isinstance(pred, dict):\n",
    "                    token_str = pred.get('token_str', '').strip()\n",
    "                    if token_str:\n",
    "                        words[mask_index] = token_str\n",
    "            else:\n",
    "                print(\"⚠️ Beklenmeyen çıktı formatı:\", predictions)\n",
    "                break\n",
    "        \n",
    "        new_text = \" \".join(words)\n",
    "        augmented_texts.add(new_text)\n",
    "    \n",
    "    return list(augmented_texts)\n",
    "\n",
    "\n",
    "original_text = \"\"\"\n",
    "Ayaküstü üye kazandılar Saadet Partisi il Başkan Yardımcısı Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sırasında iznik esnaflarından partiye üye olmak isteyen \n",
    "Osman Yıldız adlı vatandaşa kendi rozetini çıkartarak taktı. Üye olan Osman Yıldız \n",
    "Saadet Partisini yakından takip ediyorum. Geriye dönük Rahmetli Erbakan Hocaya duyduğum \n",
    "sevgi ve saygımdan dolayı ülkemiz menfaatlerini düşünerek işçi memur haklarını tam hakkı \n",
    "ile savunarak mili görüş çatısı altında buluşturdu. Bende milli görüş davasında çalışacağım...\n",
    "\"\"\"\n",
    "\n",
    "augmented_versions = augment_text_with_berturk(original_text, num_variations=3)\n",
    "\n",
    "\n",
    "def calculate_similarity(original_text, augmented_texts):\n",
    "    texts = [original_text] + augmented_texts\n",
    "    vectorizer = CountVectorizer().fit_transform(texts)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(1, len(cosine_matrix)):\n",
    "        similarities.append(cosine_matrix[0][i])\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "similarity_scores = calculate_similarity(original_text, augmented_versions)\n",
    "\n",
    "print(\"🎯 **Oluşturulan Varyasyonlar ve Benzerlik Skorları:**\")\n",
    "for i, (text, score) in enumerate(zip(augmented_versions, similarity_scores)):\n",
    "    print(f\"\\n📝 **Varyasyon {i+1}:** {text}\")\n",
    "    print(f\"🔗 **Benzerlik Skoru:** {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###llama3-8b-8192\n",
    "\n",
    "GROQ_API_KEY = \"GROQ_API_KEY\"\n",
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "original_text = \"\"\"\n",
    "Ayaküstü üye kazandılar Saadet Partisi il Başkan Yardımcısı Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sırasında iznik esnaflarından partiye üye olmak isteyen \n",
    "Osman Yıldız adlı vatandaşa kendi rozetini çıkartarak taktı. Üye olan Osman Yıldız \n",
    "Saadet Partisini yakından takip ediyorum. Geriye dönük Rahmetli Erbakan Hocaya duyduğum \n",
    "sevgi ve saygımdan dolayı ülkemiz menfaatlerini düşünerek işçi memur haklarını tam hakkı \n",
    "ile savunarak mili görüş çatısı altında buluşturdu. Bende milli görüş davasında çalışacağım...\n",
    "\"\"\" \n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Bu metni anlamını kaybetmeden yeniden Türkçe yaz: {original_text}\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###Mixtral-8x7b-32768\n",
    "\n",
    "GROQ_API_KEY = \"GROQ_API_KEY\"\n",
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "original_text = \"\"\"\n",
    "Ayaküstü üye kazandılar Saadet Partisi il Başkan Yardımcısı Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sırasında iznik esnaflarından partiye üye olmak isteyen \n",
    "Osman Yıldız adlı vatandaşa kendi rozetini çıkartarak taktı. Üye olan Osman Yıldız \n",
    "Saadet Partisini yakından takip ediyorum. Geriye dönük Rahmetli Erbakan Hocaya duyduğum \n",
    "sevgi ve saygımdan dolayı ülkemiz menfaatlerini düşünerek işçi memur haklarını tam hakkı \n",
    "ile savunarak mili görüş çatısı altında buluşturdu. Bende milli görüş davasında çalışacağım...\n",
    "\"\"\" \n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Bu metni anlamını kaybetmeden yeniden Türkçe yaz: {original_text}\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"ytu-ce-cosmos/turkish-gpt2-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "input_text = \"\"\"\n",
    "Ayaküstü üye kazandılar Saadet Partisi il Başkan Yardımcısı Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sırasında iznik esnaflarından partiye üye olmak isteyen \n",
    "Osman Yıldız adlı vatandaşa kendi rozetini çıkartarak taktı. Üye olan Osman Yıldız \n",
    "Saadet Partisini yakından takip ediyorum. Geriye dönük Rahmetli Erbakan Hocaya duyduğum \n",
    "sevgi ve saygımdan dolayı ülkemiz menfaatlerini düşünerek işçi memur haklarını tam hakkı \n",
    "ile savunarak mili görüş çatısı altında buluşturdu. Bende milli görüş davasında çalışacağım...\n",
    "\"\"\" \n",
    "\n",
    "prompt = f\"Aşağıdaki cümleyi anlamını koruyarak yeniden ifade et:\\n{input_text}\\nYeniden ifade edilmiş hali:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=256,\n",
    "    num_return_sequences=1,\n",
    "    temperature=0.6,  # Çıktı çeşitliliği\n",
    "    top_p=0.9,        # Olasılığı yüksek token'lara odaklanma\n",
    "    do_sample=True,   # Rastgele seçim etkinleştir\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "augmented_text = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Yeniden ifade edilmiş hali:\")[-1].strip()\n",
    "\n",
    "print(\"Orijinal Metin:\", input_text)\n",
    "print(\"Augmente Edilmiş Metin:\", augmented_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:00.964331Z",
     "iopub.status.busy": "2025-01-11T06:49:00.964103Z",
     "iopub.status.idle": "2025-01-11T06:49:02.038592Z",
     "shell.execute_reply": "2025-01-11T06:49:02.037934Z",
     "shell.execute_reply.started": "2025-01-11T06:49:00.964310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "news_dataset = kagglehub.dataset_download('busragural/news-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:02.039466Z",
     "iopub.status.busy": "2025-01-11T06:49:02.039278Z",
     "iopub.status.idle": "2025-01-11T06:49:16.578995Z",
     "shell.execute_reply": "2025-01-11T06:49:16.578087Z",
     "shell.execute_reply.started": "2025-01-11T06:49:02.039448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "import random\n",
    "from transformers import pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:16.911008Z",
     "iopub.status.busy": "2025-01-11T06:49:16.910705Z",
     "iopub.status.idle": "2025-01-11T06:49:16.966116Z",
     "shell.execute_reply": "2025-01-11T06:49:16.965192Z",
     "shell.execute_reply.started": "2025-01-11T06:49:16.910958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:20.637288Z",
     "iopub.status.busy": "2025-01-11T06:49:20.636958Z",
     "iopub.status.idle": "2025-01-11T06:49:20.642842Z",
     "shell.execute_reply": "2025-01-11T06:49:20.642146Z",
     "shell.execute_reply.started": "2025-01-11T06:49:20.637264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install GPUtil\n",
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:20.935559Z",
     "iopub.status.busy": "2025-01-11T06:49:20.935209Z",
     "iopub.status.idle": "2025-01-11T06:49:43.104768Z",
     "shell.execute_reply": "2025-01-11T06:49:43.103896Z",
     "shell.execute_reply.started": "2025-01-11T06:49:20.935525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(news_dataset, '/kaggle/input/news-dataset/interpress_news_category_tr_270k_train.tsv') \n",
    "df = pd.read_csv(dataset_path, sep = '\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:43.106138Z",
     "iopub.status.busy": "2025-01-11T06:49:43.105800Z",
     "iopub.status.idle": "2025-01-11T06:49:43.119755Z",
     "shell.execute_reply": "2025-01-11T06:49:43.118826Z",
     "shell.execute_reply.started": "2025-01-11T06:49:43.106107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['CategoryCode'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:43.121747Z",
     "iopub.status.busy": "2025-01-11T06:49:43.121516Z",
     "iopub.status.idle": "2025-01-11T06:49:43.198610Z",
     "shell.execute_reply": "2025-01-11T06:49:43.197674Z",
     "shell.execute_reply.started": "2025-01-11T06:49:43.121727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:43.200174Z",
     "iopub.status.busy": "2025-01-11T06:49:43.199878Z",
     "iopub.status.idle": "2025-01-11T06:49:52.675145Z",
     "shell.execute_reply": "2025-01-11T06:49:52.674210Z",
     "shell.execute_reply.started": "2025-01-11T06:49:43.200143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "\n",
    "def truncate_texts_in_dataframe(df, text_column, tokenizer, max_length=512):\n",
    "    df[text_column] = df[text_column].apply(lambda x: tokenizer.decode(tokenizer(x, truncation=True, max_length=max_length)['input_ids'], skip_special_tokens=True))\n",
    "    return df\n",
    "\n",
    "train_df = df.groupby('CategoryCode').apply(lambda x: x.sample(n=20, random_state=1)).reset_index(drop=True)\n",
    "remaining_df = pd.concat([df, train_df]).drop_duplicates(keep=False)\n",
    "test_df = remaining_df.groupby('CategoryCode').apply(lambda x: x.sample(n=20, random_state=1)).reset_index(drop=True)\n",
    "\n",
    "train_df = truncate_texts_in_dataframe(train_df, 'Content', tokenizer)\n",
    "test_df = truncate_texts_in_dataframe(test_df, 'Content', tokenizer)\n",
    "\n",
    "print(f\"✅ Train set: {len(train_df)} sample\")\n",
    "print(f\"✅ Test set: {len(test_df)} sample\")\n",
    "\n",
    "train_df.to_csv(\"trainSet.csv\", index=False)\n",
    "test_df.to_csv(\"testSet.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:52.676487Z",
     "iopub.status.busy": "2025-01-11T06:49:52.676167Z",
     "iopub.status.idle": "2025-01-11T06:49:52.680984Z",
     "shell.execute_reply": "2025-01-11T06:49:52.680126Z",
     "shell.execute_reply.started": "2025-01-11T06:49:52.676455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_models = {\n",
    "    \"minilm\": \"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "    #\"jina\": \"jinaai/jina-embeddings-v3\",\n",
    "    #\"bge\": \"BAAI/bge-m3\"\n",
    "    }\n",
    "classifiers = {\n",
    "    #\"SVM\": SVC(),\n",
    "    #\"RandomForest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=100,   # Ağaç sayısı\n",
    "        max_depth=6,        # Maksimum derinlik\n",
    "        learning_rate=0.1,  # Öğrenme oranı\n",
    "        subsample=0.8,      # Rastgele örnekleme oranı\n",
    "        colsample_bytree=0.8,  # Her ağaç için rastgele özellik oranı\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "    #\"MLP\": MLPClassifier(max_iter=500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:52.682113Z",
     "iopub.status.busy": "2025-01-11T06:49:52.681818Z",
     "iopub.status.idle": "2025-01-11T06:49:52.696669Z",
     "shell.execute_reply": "2025-01-11T06:49:52.695813Z",
     "shell.execute_reply.started": "2025-01-11T06:49:52.682085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#rm -rf /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:52.697596Z",
     "iopub.status.busy": "2025-01-11T06:49:52.697359Z",
     "iopub.status.idle": "2025-01-11T06:49:52.714841Z",
     "shell.execute_reply": "2025-01-11T06:49:52.713922Z",
     "shell.execute_reply.started": "2025-01-11T06:49:52.697575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model_name, batch_size=32, max_length=512):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            list(batch_texts),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().type(torch.float32).numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_embeddings_and_save(texts, model_name, output_file, batch_size=32):\n",
    "    embeddings = get_embeddings(texts, model_name, batch_size=batch_size)\n",
    "    np.save(output_file, embeddings)\n",
    "    print(f\"Embeddings are saved to {output_file}.\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:59.136293Z",
     "iopub.status.busy": "2025-01-11T06:49:59.135921Z",
     "iopub.status.idle": "2025-01-11T06:50:27.398103Z",
     "shell.execute_reply": "2025-01-11T06:50:27.397305Z",
     "shell.execute_reply.started": "2025-01-11T06:49:59.136263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for model_key, model_name in embedding_models.items():\n",
    "    print(f\"\\nCreating embeddings for Model: {model_name}..\")\n",
    "    \n",
    "    model_folder = f\"embeddings/{model_key}\"\n",
    "    os.makedirs(f\"{model_folder}/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{model_folder}/test\", exist_ok=True)\n",
    "    \n",
    "    # Train Embeddings\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        train_embeddings_file = os.path.join(model_folder, \"train\", f\"embeddings_{topic}.npy\")\n",
    "        if not os.path.exists(train_embeddings_file):\n",
    "            topic_texts = train_df[train_df['CategoryCode'] == topic]['Content']\n",
    "            get_embeddings_and_save(topic_texts, model_name, train_embeddings_file)\n",
    "        else:\n",
    "            print(f\"ℹ️ {train_embeddings_file} already existed.\")\n",
    "    \n",
    "    # Test Embeddings\n",
    "    for topic in test_df['CategoryCode'].unique():\n",
    "        test_embeddings_file = os.path.join(model_folder, \"test\", f\"embeddings_{topic}.npy\")\n",
    "        if not os.path.exists(test_embeddings_file):\n",
    "            topic_texts = test_df[test_df['CategoryCode'] == topic]['Content']\n",
    "            get_embeddings_and_save(topic_texts, model_name, test_embeddings_file)\n",
    "        else:\n",
    "            print(f\"ℹ️ {test_embeddings_file} already existed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:50:27.399803Z",
     "iopub.status.busy": "2025-01-11T06:50:27.399489Z",
     "iopub.status.idle": "2025-01-11T06:50:48.698355Z",
     "shell.execute_reply": "2025-01-11T06:50:48.697432Z",
     "shell.execute_reply.started": "2025-01-11T06:50:27.399776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850,680,510,340,170,85]\n",
    "data_sizes = [340, 204,136, 68]\n",
    "test_embeddings = []\n",
    "test_labels = []\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"/kaggle/working/embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    test_embeddings.append(embeddings)\n",
    "    test_labels += [topic] * len(embeddings)\n",
    "\n",
    "test_embeddings = np.vstack(test_embeddings)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Training\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nData size: {size}\")\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(embeddings)\n",
    "        train_labels += [topic] * len(embeddings)\n",
    "    \n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        predictions = clf.predict(test_embeddings)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "        print(f\"🔄 {clf_name}: Accuracy={accuracy:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1_score\": f1\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:50:48.700273Z",
     "iopub.status.busy": "2025-01-11T06:50:48.699933Z",
     "iopub.status.idle": "2025-01-11T06:50:49.070476Z",
     "shell.execute_reply": "2025-01-11T06:50:49.069556Z",
     "shell.execute_reply.started": "2025-01-11T06:50:48.700248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_vs_data_size(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for clf_name in classifiers.keys():\n",
    "        accuracies = []\n",
    "        for size in data_sizes:\n",
    "            clf_result = next((res for res in results[size] if res['classifier'] == clf_name), None)\n",
    "            if clf_result:\n",
    "                accuracies.append(clf_result['accuracy'])\n",
    "            else:\n",
    "                accuracies.append(None)\n",
    "        \n",
    "        plt.plot(data_sizes, accuracies, marker='o', linestyle='-', label=f\"{clf_name}\")\n",
    "        \n",
    "        for i, acc in enumerate(accuracies):\n",
    "            if acc is not None:\n",
    "                plt.text(data_sizes[i], acc, f\"{acc:.2f}\", \n",
    "                         fontsize=8, color='black', ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Effect of Training Dataset Sizes on Test Accuracy')\n",
    "    plt.xlabel('Dataset Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(data_sizes)\n",
    "    plt.legend(title='Classifiers')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy_vs_data_size(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:13.302854Z",
     "iopub.status.busy": "2025-01-11T06:11:13.302566Z",
     "iopub.status.idle": "2025-01-11T06:11:13.344468Z",
     "shell.execute_reply": "2025-01-11T06:11:13.343574Z",
     "shell.execute_reply.started": "2025-01-11T06:11:13.302833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# DBMDZ BERT Pipeline\n",
    "mask_filler = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-turkish-cased\", device=device)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "def augment_text_with_berturk(text, num_variations=3, max_length=512):\n",
    "    augmented_texts = set()\n",
    "    tokenizer = mask_filler.tokenizer  # Mask filler'dan tokenizer alın\n",
    "    text = truncate_text(text, tokenizer, max_length=max_length)  # Metni kısalt\n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        words = text.split() \n",
    "        x = max(1, len(words))\n",
    "\n",
    "        for i in range(x):\n",
    "            masked_text = words.copy()\n",
    "            mask_index = random.randint(0, len(masked_text) - 1)\n",
    "            masked_text[mask_index] = \"[MASK]\"\n",
    "            masked_sentence = \" \".join(masked_text)\n",
    "            \n",
    "            # Uzunluk kontrolü\n",
    "            if len(tokenizer(masked_sentence)['input_ids']) > 512:\n",
    "                print(\"⚠️ Masked sentence too long, skipping:\", masked_sentence)\n",
    "                continue\n",
    "\n",
    "            \n",
    "            predictions = mask_filler(masked_sentence)\n",
    "            if isinstance(predictions, list) and len(predictions) > 0:\n",
    "                pred = predictions[0]  # İlk tahmini al\n",
    "                if isinstance(pred, dict):\n",
    "                    token_str = pred.get('token_str', '').strip()\n",
    "                    if token_str:\n",
    "                        words[mask_index] = token_str\n",
    "            else:\n",
    "                print(\"⚠️ Beklenmeyen çıktı formatı:\", predictions)\n",
    "                break\n",
    "        \n",
    "        new_text = \" \".join(words)\n",
    "        augmented_texts.add(new_text)\n",
    "    \n",
    "    return list(augmented_texts)\n",
    "def truncate_text(text, tokenizer, max_length=512):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) > max_length:\n",
    "        truncated_tokens = tokens[:max_length]\n",
    "        truncated_text = tokenizer.convert_tokens_to_string(truncated_tokens)\n",
    "        return truncated_text\n",
    "    return text\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:13.345533Z",
     "iopub.status.busy": "2025-01-11T06:11:13.345256Z",
     "iopub.status.idle": "2025-01-11T06:11:13.360988Z",
     "shell.execute_reply": "2025-01-11T06:11:13.360244Z",
     "shell.execute_reply.started": "2025-01-11T06:11:13.345499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def majority_voting(original_pred, aug_preds):\n",
    "    votes = aug_preds + [original_pred]\n",
    "    return max(set(votes), key=votes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:13.362193Z",
     "iopub.status.busy": "2025-01-11T06:11:13.361913Z",
     "iopub.status.idle": "2025-01-11T06:11:17.959424Z",
     "shell.execute_reply": "2025-01-11T06:11:17.958421Z",
     "shell.execute_reply.started": "2025-01-11T06:11:13.362164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import random\n",
    "\n",
    "def lowercase_turkish(text):\n",
    "    \"\"\"\n",
    "    Converts text to lowercase for Turkish language, handling special case for 'I'.\n",
    "    \"\"\"\n",
    "    return text.replace(\"I\", \"ı\").lower()\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "mask_filler = pipeline(\"fill-mask\", model=\"ytu-ce-cosmos/turkish-base-bert-uncased\", device=device)\n",
    "\n",
    "def augment_text_with_berturk(text, num_variations=3, max_length=512):\n",
    "    augmented_texts = set()\n",
    "    tokenizer = mask_filler.tokenizer \n",
    "    text = lowercase_turkish(text)  \n",
    "    text = truncate_text(text, tokenizer, max_length=max_length)  \n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        words = text.split() \n",
    "        x = max(1, len(words)// 3)\n",
    "\n",
    "        for i in range(x):\n",
    "            masked_text = words.copy()\n",
    "            mask_index = random.randint(0, len(masked_text) - 1)\n",
    "            masked_text[mask_index] = \"[MASK]\"\n",
    "            masked_sentence = \" \".join(masked_text)\n",
    "            \n",
    "            if len(tokenizer(masked_sentence)['input_ids']) > 512:\n",
    "                print(\"⚠️ Masked sentence too long, skipping:\", masked_sentence)\n",
    "                continue\n",
    "\n",
    "            predictions = mask_filler(masked_sentence)\n",
    "            if isinstance(predictions, list) and len(predictions) > 0:\n",
    "                pred = predictions[0]  \n",
    "                if isinstance(pred, dict):\n",
    "                    token_str = pred.get('token_str', '').strip()\n",
    "                    if token_str:\n",
    "                        words[mask_index] = token_str\n",
    "            else:\n",
    "                print(\"⚠️ Beklenmeyen çıktı formatı:\", predictions)\n",
    "                break\n",
    "        \n",
    "        new_text = \" \".join(words)\n",
    "        augmented_texts.add(new_text)\n",
    "    \n",
    "    return list(augmented_texts)\n",
    "\n",
    "def truncate_text(text, tokenizer, max_length=512):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) > max_length:\n",
    "        truncated_tokens = tokens[:max_length]\n",
    "        truncated_text = tokenizer.convert_tokens_to_string(truncated_tokens)\n",
    "        return truncated_text\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-10T21:16:37.264738Z",
     "iopub.status.idle": "2025-01-10T21:16:37.265006Z",
     "shell.execute_reply": "2025-01-10T21:16:37.264898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_3 = augment_text_with_berturk(text, num_variations=3)\n",
    "        print(\"3 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/bert/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Augmented texts saved to {aug_texts_3_file}.\")\n",
    "\n",
    "        aug_embeddings_3 = get_embeddings(aug_texts_3, embedding_models['minilm'])\n",
    "        print(\"Yeni 3 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Augmented embeddings saved to {aug_embeddings_3_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-09T18:13:17.144063Z",
     "iopub.status.busy": "2025-01-09T18:13:17.143809Z",
     "iopub.status.idle": "2025-01-09T18:22:37.486263Z",
     "shell.execute_reply": "2025-01-09T18:22:37.485339Z",
     "shell.execute_reply.started": "2025-01-09T18:13:17.144042Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_berturk(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/bert/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "\n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"Yeni 5 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:17.960631Z",
     "iopub.status.busy": "2025-01-11T06:11:17.960326Z",
     "iopub.status.idle": "2025-01-11T06:25:44.163178Z",
     "shell.execute_reply": "2025-01-11T06:25:44.162312Z",
     "shell.execute_reply.started": "2025-01-11T06:11:17.960609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    \n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_berturk(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/bert/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "        \n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"5 Embedding oluşturuldu.\")\n",
    "        \n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")\n",
    "        \n",
    "        selected_indices = random.sample(range(5), 3)\n",
    "        aug_texts_3 = [aug_texts_5[i] for i in selected_indices]\n",
    "        aug_embeddings_3 = [aug_embeddings_5[i] for i in selected_indices]\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/bert/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)  \n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Selected augmented texts saved to {aug_texts_3_file}.\")\n",
    "        \n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)  \n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Selected augmented embeddings saved to {aug_embeddings_3_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:25:44.164589Z",
     "iopub.status.busy": "2025-01-11T06:25:44.164244Z",
     "iopub.status.idle": "2025-01-11T06:26:05.775103Z",
     "shell.execute_reply": "2025-01-11T06:26:05.774266Z",
     "shell.execute_reply.started": "2025-01-11T06:25:44.164555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"🔄 {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_5 = []\n",
    "        augmented_test_predictions_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_5_file = f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_5 = np.load(aug_embeddings_5_file)\n",
    "\n",
    "                aug_embeddings_3_file = f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_3 = np.load(aug_embeddings_3_file)\n",
    "\n",
    "                aug_preds_5 = clf.predict(aug_embeddings_5)\n",
    "\n",
    "                aug_preds_3 = clf.predict(aug_embeddings_3)\n",
    "\n",
    "                final_pred_5 = majority_voting(original_pred, aug_preds_5.tolist())\n",
    "                augmented_test_predictions_5.append(final_pred_5)\n",
    "\n",
    "                final_pred_3 = majority_voting(original_pred, aug_preds_3.tolist())\n",
    "                augmented_test_predictions_3.append(final_pred_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_5 = accuracy_score(test_labels, augmented_test_predictions_5)\n",
    "        augmented_accuracy_3 = accuracy_score(test_labels, augmented_test_predictions_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_5\": augmented_accuracy_5,\n",
    "            \"augmented_accuracy_3\": augmented_accuracy_3\n",
    "        })\n",
    "        print(f\"✅ {clf_name} - Original Accuracy: {original_accuracy:.4f}, Augmented Accuracy (5): {augmented_accuracy_5:.4f}, Augmented Accuracy (3): {augmented_accuracy_3:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_5 = [next((res['augmented_accuracy_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_3 = [next((res['augmented_accuracy_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_5, marker='x', linestyle='--', label=f\"{clf_name} - Augmented (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_3, marker='s', linestyle='-.', label=f\"{clf_name} - Augmented (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:26:05.776481Z",
     "iopub.status.busy": "2025-01-11T06:26:05.776124Z",
     "iopub.status.idle": "2025-01-11T06:26:11.038281Z",
     "shell.execute_reply": "2025-01-11T06:26:11.037368Z",
     "shell.execute_reply.started": "2025-01-11T06:26:05.776449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:26:11.039620Z",
     "iopub.status.busy": "2025-01-11T06:26:11.039357Z",
     "iopub.status.idle": "2025-01-11T06:26:11.389485Z",
     "shell.execute_reply": "2025-01-11T06:26:11.388717Z",
     "shell.execute_reply.started": "2025-01-11T06:26:11.039598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###llama3-8b-8192\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "GROQ_API_KEY = \"\"\n",
    "\n",
    "def augment_text_with_llama(text, num_variations=3):\n",
    "    client = Groq(api_key=GROQ_API_KEY)\n",
    "    augmented_texts = set()\n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Bu metni anlamını kaybetmeden yeniden Türkçe yaz ve yalnızca yeni metni yaz: {text}\",\n",
    "                    }\n",
    "                ],\n",
    "                model=\"llama3-8b-8192\",\n",
    "            )\n",
    "            generated_text = chat_completion.choices[0].message.content.strip()\n",
    "            augmented_texts.add(generated_text)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error during augmentation: {e}\")\n",
    "\n",
    "    return list(augmented_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-09T19:56:12.452221Z",
     "iopub.status.idle": "2025-01-09T19:56:12.452447Z",
     "shell.execute_reply": "2025-01-09T19:56:12.452351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "aug_texts_3 = augment_text_with_llama(test_df.iloc[0]['Content'], num_variations=3)\n",
    "aug_texts_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-09T17:34:47.218368Z",
     "iopub.status.busy": "2025-01-09T17:34:47.218075Z",
     "iopub.status.idle": "2025-01-09T17:36:07.878275Z",
     "shell.execute_reply": "2025-01-09T17:36:07.877272Z",
     "shell.execute_reply.started": "2025-01-09T17:34:47.218346Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_3 = augment_text_with_llama(text, num_variations=3)\n",
    "        print(\"3 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/llama/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Augmented texts saved to {aug_texts_3_file}.\")\n",
    "\n",
    "        aug_embeddings_3 = get_embeddings(aug_texts_3, embedding_models['minilm'])\n",
    "        print(\"Yeni 3 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Augmented embeddings saved to {aug_embeddings_3_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-09T17:36:26.071690Z",
     "iopub.status.busy": "2025-01-09T17:36:26.071344Z",
     "iopub.status.idle": "2025-01-09T17:39:52.239193Z",
     "shell.execute_reply": "2025-01-09T17:39:52.238377Z",
     "shell.execute_reply.started": "2025-01-09T17:36:26.071662Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_llama(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/llama/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "\n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"Yeni 5 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:26:11.392468Z",
     "iopub.status.busy": "2025-01-11T06:26:11.392182Z",
     "iopub.status.idle": "2025-01-11T06:32:24.243395Z",
     "shell.execute_reply": "2025-01-11T06:32:24.242476Z",
     "shell.execute_reply.started": "2025-01-11T06:26:11.392443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    \n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_llama(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/llama/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "        \n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"5 Embedding oluşturuldu.\")\n",
    "        \n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")\n",
    "        \n",
    "        selected_indices = random.sample(range(5), 3)\n",
    "        aug_texts_3 = [aug_texts_5[i] for i in selected_indices]\n",
    "        aug_embeddings_3 = [aug_embeddings_5[i] for i in selected_indices]\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/llama/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True) \n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Selected augmented texts saved to {aug_texts_3_file}.\")\n",
    "        \n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)  \n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Selected augmented embeddings saved to {aug_embeddings_3_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:32:24.245109Z",
     "iopub.status.busy": "2025-01-11T06:32:24.244761Z",
     "iopub.status.idle": "2025-01-11T06:32:45.429084Z",
     "shell.execute_reply": "2025-01-11T06:32:45.428202Z",
     "shell.execute_reply.started": "2025-01-11T06:32:24.245071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"🔄 {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_5 = []\n",
    "        augmented_test_predictions_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_5_file = f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_5 = np.load(aug_embeddings_5_file)\n",
    "\n",
    "                aug_embeddings_3_file = f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_3 = np.load(aug_embeddings_3_file)\n",
    "\n",
    "                aug_preds_5 = clf.predict(aug_embeddings_5)\n",
    "\n",
    "                aug_preds_3 = clf.predict(aug_embeddings_3)\n",
    "\n",
    "                final_pred_5 = majority_voting(original_pred, aug_preds_5.tolist())\n",
    "                augmented_test_predictions_5.append(final_pred_5)\n",
    "\n",
    "                final_pred_3 = majority_voting(original_pred, aug_preds_3.tolist())\n",
    "                augmented_test_predictions_3.append(final_pred_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_5 = accuracy_score(test_labels, augmented_test_predictions_5)\n",
    "        augmented_accuracy_3 = accuracy_score(test_labels, augmented_test_predictions_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_5\": augmented_accuracy_5,\n",
    "            \"augmented_accuracy_3\": augmented_accuracy_3\n",
    "        })\n",
    "        print(f\"✅ {clf_name} - Original Accuracy: {original_accuracy:.4f}, Augmented Accuracy (5): {augmented_accuracy_5:.4f}, Augmented Accuracy (3): {augmented_accuracy_3:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_5 = [next((res['augmented_accuracy_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_3 = [next((res['augmented_accuracy_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_5, marker='x', linestyle='--', label=f\"{clf_name} - Augmented (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_3, marker='s', linestyle='-.', label=f\"{clf_name} - Augmented (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:46:51.102524Z",
     "iopub.status.busy": "2025-01-09T17:46:51.102198Z",
     "iopub.status.idle": "2025-01-09T17:47:27.629330Z",
     "shell.execute_reply": "2025-01-09T17:47:27.628422Z",
     "shell.execute_reply.started": "2025-01-09T17:46:51.102500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name=\"ytu-ce-cosmos/turkish-gpt2-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    " # GPU desteği varsa modele taşı\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def augment_text_with_gpt2(input_text, num_variations=3 ):\n",
    "    augmented_texts = set()\n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        # Augmentation için prompt hazırla\n",
    "        prompt = f\"Aşağıdaki cümleyi anlamını koruyarak yeniden ifade et:\\n{input_text}\\nYeniden ifade edilmiş hali:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Modelden çıktı üret\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        # Çıktıyı çözümle ve ekle\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Yeniden ifade edilmiş hali:\")[-1].strip()\n",
    "        augmented_texts.add(generated_text)\n",
    "\n",
    "    return list(augmented_texts)\n",
    "        \n",
    "\n",
    "# Örnek kullanım\n",
    "original_text = \"\"\"\n",
    "Ayaküstü üye kazandılar Saadet Partisi il Başkan Yardımcısı Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sırasında iznik esnaflarından partiye üye olmak isteyen \n",
    "Osman Yıldız adlı vatandaşa kendi rozetini çıkartarak taktı. Üye olan Osman Yıldız \n",
    "Saadet Partisini yakından takip ediyorum. Geriye dönük Rahmetli Erbakan Hocaya duyduğum \n",
    "sevgi ve saygımdan dolayı ülkemiz menfaatlerini düşünerek işçi memur haklarını tam hakkı \n",
    "ile savunarak mili görüş çatısı altında buluşturdu. Bende milli görüş davasında çalışacağım...\n",
    "\"\"\"\n",
    "\n",
    "augmented_texts = augment_text_with_gpt2(original_text, num_variations=3)\n",
    "for idx, text in enumerate(augmented_texts, start=1):\n",
    "    print(f\"Varyasyon {idx}: {text}\\n\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:47:48.802896Z",
     "iopub.status.busy": "2025-01-09T17:47:48.802582Z",
     "iopub.status.idle": "2025-01-09T17:48:23.798528Z",
     "shell.execute_reply": "2025-01-09T17:48:23.797741Z",
     "shell.execute_reply.started": "2025-01-09T17:47:48.802872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "aug_texts_3 = augment_text_with_gpt2(test_df.iloc[0]['Content'], num_variations=3)\n",
    "aug_texts_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:32:45.430143Z",
     "iopub.status.busy": "2025-01-11T06:32:45.429907Z",
     "iopub.status.idle": "2025-01-11T06:33:24.653524Z",
     "shell.execute_reply": "2025-01-11T06:33:24.652624Z",
     "shell.execute_reply.started": "2025-01-11T06:32:45.430123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"ytu-ce-cosmos/turkish-gpt2-medium-350m-instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def augment_text_with_gpt2(input_text, num_variations=3):\n",
    "    augmented_texts = set()\n",
    "    max_length = model.config.max_position_embeddings\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        prompt = f\"Aşağıdaki cümleyi anlamını koruyarak yeniden ifade et:\\n{input_text}\\nYeniden ifade edilmiş hali:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Yeniden ifade edilmiş hali:\")[-1].strip()\n",
    "        augmented_texts.add(generated_text)\n",
    "\n",
    "    return list(augmented_texts)\n",
    "\n",
    "aug_texts_3 = augment_text_with_gpt2(test_df.iloc[2]['Content'], num_variations=3)\n",
    "aug_texts_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:54:13.133203Z",
     "iopub.status.busy": "2025-01-09T17:54:13.132841Z",
     "iopub.status.idle": "2025-01-09T17:56:16.411399Z",
     "shell.execute_reply": "2025-01-09T17:56:16.410518Z",
     "shell.execute_reply.started": "2025-01-09T17:54:13.133174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_3 = augment_text_with_gpt2(text, num_variations=3)\n",
    "        print(\"3 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/gpt2/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Augmented texts saved to {aug_texts_3_file}.\")\n",
    "\n",
    "        aug_embeddings_3 = get_embeddings(aug_texts_3, embedding_models['minilm'])\n",
    "        print(\"Yeni 3 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Augmented embeddings saved to {aug_embeddings_3_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:56:27.417588Z",
     "iopub.status.busy": "2025-01-09T17:56:27.417285Z",
     "iopub.status.idle": "2025-01-09T17:59:09.163794Z",
     "shell.execute_reply": "2025-01-09T17:59:09.162868Z",
     "shell.execute_reply.started": "2025-01-09T17:56:27.417564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_gpt2(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/gpt2/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "\n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"Yeni 5 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:33:24.654563Z",
     "iopub.status.busy": "2025-01-11T06:33:24.654310Z",
     "iopub.status.idle": "2025-01-11T06:36:41.675753Z",
     "shell.execute_reply": "2025-01-11T06:36:41.674963Z",
     "shell.execute_reply.started": "2025-01-11T06:33:24.654542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    \n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_gpt2(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapıldı.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/gpt2/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "        \n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"5 Embedding oluşturuldu.\")\n",
    "        \n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")\n",
    "        \n",
    "        selected_indices = random.sample(range(5), 3)\n",
    "        aug_texts_3 = [aug_texts_5[i] for i in selected_indices]\n",
    "        aug_embeddings_3 = [aug_embeddings_5[i] for i in selected_indices]\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/gpt2/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)  # Dizini oluştur\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Selected augmented texts saved to {aug_texts_3_file}.\")\n",
    "        \n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)  # Dizini oluştur\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Selected augmented embeddings saved to {aug_embeddings_3_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:36:41.676861Z",
     "iopub.status.busy": "2025-01-11T06:36:41.676605Z",
     "iopub.status.idle": "2025-01-11T06:37:03.069298Z",
     "shell.execute_reply": "2025-01-11T06:37:03.068455Z",
     "shell.execute_reply.started": "2025-01-11T06:36:41.676839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Train classifiers\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"🔄 {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_5 = []\n",
    "        augmented_test_predictions_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_5_file = f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_5 = np.load(aug_embeddings_5_file)\n",
    "\n",
    "                aug_embeddings_3_file = f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_3 = np.load(aug_embeddings_3_file)\n",
    "\n",
    "                aug_preds_5 = clf.predict(aug_embeddings_5)\n",
    "\n",
    "                aug_preds_3 = clf.predict(aug_embeddings_3)\n",
    "\n",
    "                final_pred_5 = majority_voting(original_pred, aug_preds_5.tolist())\n",
    "                augmented_test_predictions_5.append(final_pred_5)\n",
    "\n",
    "                final_pred_3 = majority_voting(original_pred, aug_preds_3.tolist())\n",
    "                augmented_test_predictions_3.append(final_pred_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_5 = accuracy_score(test_labels, augmented_test_predictions_5)\n",
    "        augmented_accuracy_3 = accuracy_score(test_labels, augmented_test_predictions_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_5\": augmented_accuracy_5,\n",
    "            \"augmented_accuracy_3\": augmented_accuracy_3\n",
    "        })\n",
    "        print(f\"✅ {clf_name} - Original Accuracy: {original_accuracy:.4f}, Augmented Accuracy (5): {augmented_accuracy_5:.4f}, Augmented Accuracy (3): {augmented_accuracy_3:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_5 = [next((res['augmented_accuracy_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_3 = [next((res['augmented_accuracy_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_5, marker='x', linestyle='--', label=f\"{clf_name} - Augmented (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_3, marker='s', linestyle='-.', label=f\"{clf_name} - Augmented (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:37:03.070669Z",
     "iopub.status.busy": "2025-01-11T06:37:03.070425Z",
     "iopub.status.idle": "2025-01-11T06:37:24.235264Z",
     "shell.execute_reply": "2025-01-11T06:37:24.234452Z",
     "shell.execute_reply.started": "2025-01-11T06:37:03.070646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"🔄 {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_bert_5 = []\n",
    "        augmented_test_predictions_bert_3 = []\n",
    "        augmented_test_predictions_llama_5 = []\n",
    "        augmented_test_predictions_llama_3 = []\n",
    "        augmented_test_predictions_gpt2_5 = []\n",
    "        augmented_test_predictions_gpt2_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_bert_5 = np.load(f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_llama_5 = np.load(f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_gpt2_5 = np.load(f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\")\n",
    "\n",
    "                aug_embeddings_bert_3 = np.load(f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_llama_3 = np.load(f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_gpt2_3 = np.load(f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\")\n",
    "\n",
    "                aug_preds_bert_5 = clf.predict(aug_embeddings_bert_5)\n",
    "                aug_preds_bert_3 = clf.predict(aug_embeddings_bert_3)\n",
    "\n",
    "                aug_preds_llama_5 = clf.predict(aug_embeddings_llama_5)\n",
    "                aug_preds_llama_3 = clf.predict(aug_embeddings_llama_3)\n",
    "\n",
    "                aug_preds_gpt2_5 = clf.predict(aug_embeddings_gpt2_5)\n",
    "                aug_preds_gpt2_3 = clf.predict(aug_embeddings_gpt2_3)\n",
    "\n",
    "                final_pred_bert_5 = majority_voting(original_pred, aug_preds_bert_5.tolist())\n",
    "                final_pred_bert_3 = majority_voting(original_pred, aug_preds_bert_3.tolist())\n",
    "                final_pred_llama_5 = majority_voting(original_pred, aug_preds_llama_5.tolist())\n",
    "                final_pred_llama_3 = majority_voting(original_pred, aug_preds_llama_3.tolist())\n",
    "                final_pred_gpt2_5 = majority_voting(original_pred, aug_preds_gpt2_5.tolist())\n",
    "                final_pred_gpt2_3 = majority_voting(original_pred, aug_preds_gpt2_3.tolist())\n",
    "\n",
    "                augmented_test_predictions_bert_5.append(final_pred_bert_5)\n",
    "                augmented_test_predictions_bert_3.append(final_pred_bert_3)\n",
    "                augmented_test_predictions_llama_5.append(final_pred_llama_5)\n",
    "                augmented_test_predictions_llama_3.append(final_pred_llama_3)\n",
    "                augmented_test_predictions_gpt2_5.append(final_pred_gpt2_5)\n",
    "                augmented_test_predictions_gpt2_3.append(final_pred_gpt2_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_bert_5 = accuracy_score(test_labels, augmented_test_predictions_bert_5)\n",
    "        augmented_accuracy_bert_3 = accuracy_score(test_labels, augmented_test_predictions_bert_3)\n",
    "        augmented_accuracy_llama_5 = accuracy_score(test_labels, augmented_test_predictions_llama_5)\n",
    "        augmented_accuracy_llama_3 = accuracy_score(test_labels, augmented_test_predictions_llama_3)\n",
    "        augmented_accuracy_gpt2_5 = accuracy_score(test_labels, augmented_test_predictions_gpt2_5)\n",
    "        augmented_accuracy_gpt2_3 = accuracy_score(test_labels, augmented_test_predictions_gpt2_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_bert_5\": augmented_accuracy_bert_5,\n",
    "            \"augmented_accuracy_bert_3\": augmented_accuracy_bert_3,\n",
    "            \"augmented_accuracy_llama_5\": augmented_accuracy_llama_5,\n",
    "            \"augmented_accuracy_llama_3\": augmented_accuracy_llama_3,\n",
    "            \"augmented_accuracy_gpt2_5\": augmented_accuracy_gpt2_5,\n",
    "            \"augmented_accuracy_gpt2_3\": augmented_accuracy_gpt2_3\n",
    "        })\n",
    "        print(f\"✅ {clf_name} - Original Accuracy: {original_accuracy:.4f}, BERT-5: {augmented_accuracy_bert_5:.4f}, BERT-3: {augmented_accuracy_bert_3:.4f}, LLama-5: {augmented_accuracy_llama_5:.4f}, LLama-3: {augmented_accuracy_llama_3:.4f}, GPT2-5: {augmented_accuracy_gpt2_5:.4f}, GPT2-3: {augmented_accuracy_gpt2_3:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(14, 10))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_bert_5 = [next((res['augmented_accuracy_bert_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_bert_3 = [next((res['augmented_accuracy_bert_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_llama_5 = [next((res['augmented_accuracy_llama_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_llama_3 = [next((res['augmented_accuracy_llama_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_gpt2_5 = [next((res['augmented_accuracy_gpt2_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_gpt2_3 = [next((res['augmented_accuracy_gpt2_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_bert_5, marker='x', linestyle='--', label=f\"{clf_name} - BERT (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_bert_3, marker='s', linestyle='--', label=f\"{clf_name} - BERT (3)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_llama_5, marker='^', linestyle='-.', label=f\"{clf_name} - LLama (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_llama_3, marker='v', linestyle='-.', label=f\"{clf_name} - LLama (3)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_gpt2_5, marker='d', linestyle=':', label=f\"{clf_name} - GPT-2 (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_gpt2_3, marker='p', linestyle=':', label=f\"{clf_name} - GPT-2 (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T18:43:01.661848Z",
     "iopub.status.busy": "2025-01-09T18:43:01.661532Z",
     "iopub.status.idle": "2025-01-09T18:43:21.852581Z",
     "shell.execute_reply": "2025-01-09T18:43:21.851837Z",
     "shell.execute_reply.started": "2025-01-09T18:43:01.661826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_example = test_df.iloc[0]['Content']\n",
    "print(f\"Original Test Example: {test_example}\\n\")\n",
    "\n",
    "augmented_texts = augment_text_with_berturk(test_example, num_variations=3)\n",
    "print(\"Augmented Examples:\")\n",
    "for idx, text in enumerate(augmented_texts, start=1):\n",
    "    print(f\"  Augmented {idx}: {text}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\n=== Training with data size: {size} ===\")\n",
    "\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"  🔄 {clf_name} trained.\")\n",
    "\n",
    "        original_embedding = np.load(f\"embeddings/minilm/test/embeddings_{test_df.iloc[0]['CategoryCode']}.npy\")[0].reshape(1, -1)\n",
    "        original_prediction = clf.predict(original_embedding)[0]\n",
    "        print(f\"  {clf_name} - Original Prediction: {original_prediction}\")\n",
    "\n",
    "        augmented_embeddings = get_embeddings(augmented_texts, embedding_models['minilm'])\n",
    "        augmented_predictions = clf.predict(augmented_embeddings)\n",
    "        for idx, pred in enumerate(augmented_predictions, start=1):\n",
    "            print(f\"  {clf_name} - Augmented {idx} Prediction: {pred}\")\n",
    "\n",
    "        all_predictions = [original_prediction] + augmented_predictions.tolist()\n",
    "        final_prediction = max(set(all_predictions), key=all_predictions.count)\n",
    "        print(f\"  {clf_name} - Final Prediction (Majority Voting): {final_prediction}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:41:17.458316Z",
     "iopub.status.busy": "2025-01-10T20:41:17.458014Z",
     "iopub.status.idle": "2025-01-10T20:53:40.570963Z",
     "shell.execute_reply": "2025-01-10T20:53:40.569438Z",
     "shell.execute_reply.started": "2025-01-10T20:41:17.458293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def augment_training_data(train_texts, num_variations=4):\n",
    "    augmented_texts = []\n",
    "    for text in tqdm(train_texts, desc=\"Augmenting training data\"):\n",
    "        augmented_variations = augment_text_with_llama(text, num_variations=num_variations)\n",
    "        augmented_texts.extend(augmented_variations)\n",
    "    return augmented_texts\n",
    "\n",
    "def process_and_save_augmented_data(train_df, output_dir, model_name, num_variations=4):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_texts = train_df[train_df['CategoryCode'] == topic]['Content']\n",
    "        \n",
    "        augmented_file = os.path.join(output_dir, f\"augmented_texts_{topic}.npy\")\n",
    "        if os.path.exists(augmented_file):\n",
    "            print(f\"ℹ️ Augmented texts already exist: {augmented_file}\")\n",
    "            augmented_texts = np.load(augmented_file, allow_pickle=True).tolist()\n",
    "        else:\n",
    "            augmented_texts = augment_training_data(topic_texts, num_variations=num_variations)\n",
    "            np.save(augmented_file, np.array(augmented_texts, dtype=object))\n",
    "            print(f\"✅ Augmented texts saved: {augmented_file}\")\n",
    "\n",
    "        embeddings_file = os.path.join(output_dir, f\"embeddings_{topic}.npy\")\n",
    "        if os.path.exists(embeddings_file):\n",
    "            print(f\"ℹ️ Embeddings already exist: {embeddings_file}\")\n",
    "        else:\n",
    "            embeddings = get_embeddings(augmented_texts, model_name)\n",
    "            np.save(embeddings_file, embeddings)\n",
    "            print(f\"✅ Embeddings saved: {embeddings_file}\")\n",
    "\n",
    "train_texts = train_df['Content']\n",
    "augment_output_dir = \"augmented_data/llama\"\n",
    "process_and_save_augmented_data(train_df, augment_output_dir, embedding_models['minilm'], num_variations=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:53:59.491158Z",
     "iopub.status.busy": "2025-01-10T20:53:59.490840Z",
     "iopub.status.idle": "2025-01-10T20:55:37.272582Z",
     "shell.execute_reply": "2025-01-10T20:55:37.271793Z",
     "shell.execute_reply.started": "2025-01-10T20:53:59.491131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_augmented_train_set(original_embeddings, augmented_embeddings, num_augmentations):\n",
    "    new_train_embeddings = []\n",
    "    new_train_labels = []\n",
    "\n",
    "    for topic, orig_embed in original_embeddings.items():\n",
    "        new_train_embeddings.append(orig_embed)\n",
    "        new_train_labels += [topic] * len(orig_embed)\n",
    "\n",
    "        if topic in augmented_embeddings:\n",
    "            available_augmentations = len(augmented_embeddings[topic])\n",
    "            if available_augmentations < num_augmentations:\n",
    "                print(f\"⚠️ Warning: Not enough augmented embeddings for topic {topic}. Available: {available_augmentations}, Requested: {num_augmentations}\")\n",
    "                num_augmentations = available_augmentations\n",
    "\n",
    "            for i in range(num_augmentations):\n",
    "                new_train_embeddings.append(augmented_embeddings[topic][i])\n",
    "                new_train_labels.append(topic)\n",
    "\n",
    "    new_train_embeddings = np.vstack(new_train_embeddings)\n",
    "    new_train_labels = np.array(new_train_labels)\n",
    "\n",
    "    return new_train_embeddings, new_train_labels\n",
    "\n",
    "\n",
    "original_embeddings = {}\n",
    "augmented_embeddings = {}\n",
    "\n",
    "for topic in train_df['CategoryCode'].unique():\n",
    "    orig_file = os.path.join(\"embeddings/minilm/train\", f\"embeddings_{topic}.npy\")\n",
    "    original_embeddings[topic] = np.load(orig_file)\n",
    "\n",
    "    aug_file = os.path.join(\"augmented_data/minilm\", f\"embeddings_{topic}.npy\")\n",
    "    augmented_embeddings[topic] = np.load(aug_file)\n",
    "\n",
    "# Eğitim süreci\n",
    "results_augmented = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    subset_embeddings = {}\n",
    "    for topic, embeddings in original_embeddings.items():\n",
    "        subset_embeddings[topic] = embeddings[:size // len(original_embeddings)]\n",
    "\n",
    "    for num_aug in [0, 1, 2, 4]:\n",
    "        print(f\"\\nData size: {size}, Augmentations per example: {num_aug}\")\n",
    "\n",
    "        train_embeddings, train_labels = create_augmented_train_set(\n",
    "            subset_embeddings, augmented_embeddings, num_aug\n",
    "        )\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            clf.fit(train_embeddings, train_labels)\n",
    "            predictions = clf.predict(test_embeddings)\n",
    "            accuracy = accuracy_score(test_labels, predictions)\n",
    "            f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "\n",
    "            print(f\"🔄 {clf_name} - Accuracy={accuracy:.4f}, F1={f1:.4f}\")\n",
    "            results_augmented[size].append({\n",
    "                \"augmentations\": num_aug,\n",
    "                \"classifier\": clf_name,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"f1_score\": f1\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T21:08:14.843666Z",
     "iopub.status.busy": "2025-01-10T21:08:14.843288Z",
     "iopub.status.idle": "2025-01-10T21:08:15.231434Z",
     "shell.execute_reply": "2025-01-10T21:08:15.230552Z",
     "shell.execute_reply.started": "2025-01-10T21:08:14.843634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(results, metric=\"accuracy\"):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for clf_name in classifiers.keys():\n",
    "        for num_aug in [0, 1, 2, 4]:\n",
    "            metric_values = []\n",
    "            for size in data_sizes:\n",
    "                clf_results = [res for res in results[size] if res['classifier'] == clf_name and res['augmentations'] == num_aug]\n",
    "                if clf_results:\n",
    "                    metric_values.append(clf_results[0][metric])\n",
    "                else:\n",
    "                    metric_values.append(None)\n",
    "\n",
    "            plt.plot(data_sizes, metric_values, marker='o', label=f\"{clf_name} (Aug={num_aug})\")\n",
    "\n",
    "    plt.title(f\"Effect of Data Size and Augmentations on {metric.capitalize()}\")\n",
    "    plt.xlabel(\"Data Size\")\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend(title=\"Classifier and Augmentations\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(results_augmented, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6433546,
     "sourceId": 10385215,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
