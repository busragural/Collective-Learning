{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "mask_filler = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-turkish-cased\", device=device)\n",
    "\n",
    "\n",
    "def augment_text_with_berturk(text, num_variations=3):\n",
    "    augmented_texts = set()  \n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        words = text.split()  \n",
    "        x = max(1, len(words))\n",
    "\n",
    "        for i in range(x):\n",
    "            masked_text = words.copy()\n",
    "            \n",
    "            mask_index = random.randint(0, len(masked_text) - 1)\n",
    "            masked_text[mask_index] = \"[MASK]\"\n",
    "            masked_sentence = \" \".join(masked_text)\n",
    "            \n",
    "            predictions = mask_filler(masked_sentence)\n",
    "            \n",
    "            if isinstance(predictions, list) and len(predictions) > 0:\n",
    "                pred = predictions[0]\n",
    "                if isinstance(pred, dict):\n",
    "                    token_str = pred.get('token_str', '').strip()\n",
    "                    if token_str:\n",
    "                        words[mask_index] = token_str\n",
    "            else:\n",
    "                print(\"âš ï¸ Beklenmeyen Ã§Ä±ktÄ± formatÄ±:\", predictions)\n",
    "                break\n",
    "        \n",
    "        new_text = \" \".join(words)\n",
    "        augmented_texts.add(new_text)\n",
    "    \n",
    "    return list(augmented_texts)\n",
    "\n",
    "\n",
    "original_text = \"\"\"\n",
    "AyakÃ¼stÃ¼ Ã¼ye kazandÄ±lar Saadet Partisi il BaÅŸkan YardÄ±mcÄ±sÄ± Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sÄ±rasÄ±nda iznik esnaflarÄ±ndan partiye Ã¼ye olmak isteyen \n",
    "Osman YÄ±ldÄ±z adlÄ± vatandaÅŸa kendi rozetini Ã§Ä±kartarak taktÄ±. Ãœye olan Osman YÄ±ldÄ±z \n",
    "Saadet Partisini yakÄ±ndan takip ediyorum. Geriye dÃ¶nÃ¼k Rahmetli Erbakan Hocaya duyduÄŸum \n",
    "sevgi ve saygÄ±mdan dolayÄ± Ã¼lkemiz menfaatlerini dÃ¼ÅŸÃ¼nerek iÅŸÃ§i memur haklarÄ±nÄ± tam hakkÄ± \n",
    "ile savunarak mili gÃ¶rÃ¼ÅŸ Ã§atÄ±sÄ± altÄ±nda buluÅŸturdu. Bende milli gÃ¶rÃ¼ÅŸ davasÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±m...\n",
    "\"\"\"\n",
    "\n",
    "augmented_versions = augment_text_with_berturk(original_text, num_variations=3)\n",
    "\n",
    "\n",
    "def calculate_similarity(original_text, augmented_texts):\n",
    "    texts = [original_text] + augmented_texts\n",
    "    vectorizer = CountVectorizer().fit_transform(texts)\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(1, len(cosine_matrix)):\n",
    "        similarities.append(cosine_matrix[0][i])\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "similarity_scores = calculate_similarity(original_text, augmented_versions)\n",
    "\n",
    "print(\"ğŸ¯ **OluÅŸturulan Varyasyonlar ve Benzerlik SkorlarÄ±:**\")\n",
    "for i, (text, score) in enumerate(zip(augmented_versions, similarity_scores)):\n",
    "    print(f\"\\nğŸ“ **Varyasyon {i+1}:** {text}\")\n",
    "    print(f\"ğŸ”— **Benzerlik Skoru:** {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###llama3-8b-8192\n",
    "\n",
    "GROQ_API_KEY = \"GROQ_API_KEY\"\n",
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "original_text = \"\"\"\n",
    "AyakÃ¼stÃ¼ Ã¼ye kazandÄ±lar Saadet Partisi il BaÅŸkan YardÄ±mcÄ±sÄ± Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sÄ±rasÄ±nda iznik esnaflarÄ±ndan partiye Ã¼ye olmak isteyen \n",
    "Osman YÄ±ldÄ±z adlÄ± vatandaÅŸa kendi rozetini Ã§Ä±kartarak taktÄ±. Ãœye olan Osman YÄ±ldÄ±z \n",
    "Saadet Partisini yakÄ±ndan takip ediyorum. Geriye dÃ¶nÃ¼k Rahmetli Erbakan Hocaya duyduÄŸum \n",
    "sevgi ve saygÄ±mdan dolayÄ± Ã¼lkemiz menfaatlerini dÃ¼ÅŸÃ¼nerek iÅŸÃ§i memur haklarÄ±nÄ± tam hakkÄ± \n",
    "ile savunarak mili gÃ¶rÃ¼ÅŸ Ã§atÄ±sÄ± altÄ±nda buluÅŸturdu. Bende milli gÃ¶rÃ¼ÅŸ davasÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±m...\n",
    "\"\"\" \n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Bu metni anlamÄ±nÄ± kaybetmeden yeniden TÃ¼rkÃ§e yaz: {original_text}\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###Mixtral-8x7b-32768\n",
    "\n",
    "GROQ_API_KEY = \"GROQ_API_KEY\"\n",
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=GROQ_API_KEY,\n",
    ")\n",
    "original_text = \"\"\"\n",
    "AyakÃ¼stÃ¼ Ã¼ye kazandÄ±lar Saadet Partisi il BaÅŸkan YardÄ±mcÄ±sÄ± Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sÄ±rasÄ±nda iznik esnaflarÄ±ndan partiye Ã¼ye olmak isteyen \n",
    "Osman YÄ±ldÄ±z adlÄ± vatandaÅŸa kendi rozetini Ã§Ä±kartarak taktÄ±. Ãœye olan Osman YÄ±ldÄ±z \n",
    "Saadet Partisini yakÄ±ndan takip ediyorum. Geriye dÃ¶nÃ¼k Rahmetli Erbakan Hocaya duyduÄŸum \n",
    "sevgi ve saygÄ±mdan dolayÄ± Ã¼lkemiz menfaatlerini dÃ¼ÅŸÃ¼nerek iÅŸÃ§i memur haklarÄ±nÄ± tam hakkÄ± \n",
    "ile savunarak mili gÃ¶rÃ¼ÅŸ Ã§atÄ±sÄ± altÄ±nda buluÅŸturdu. Bende milli gÃ¶rÃ¼ÅŸ davasÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±m...\n",
    "\"\"\" \n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Bu metni anlamÄ±nÄ± kaybetmeden yeniden TÃ¼rkÃ§e yaz: {original_text}\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"mixtral-8x7b-32768\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"ytu-ce-cosmos/turkish-gpt2-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "input_text = \"\"\"\n",
    "AyakÃ¼stÃ¼ Ã¼ye kazandÄ±lar Saadet Partisi il BaÅŸkan YardÄ±mcÄ±sÄ± Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sÄ±rasÄ±nda iznik esnaflarÄ±ndan partiye Ã¼ye olmak isteyen \n",
    "Osman YÄ±ldÄ±z adlÄ± vatandaÅŸa kendi rozetini Ã§Ä±kartarak taktÄ±. Ãœye olan Osman YÄ±ldÄ±z \n",
    "Saadet Partisini yakÄ±ndan takip ediyorum. Geriye dÃ¶nÃ¼k Rahmetli Erbakan Hocaya duyduÄŸum \n",
    "sevgi ve saygÄ±mdan dolayÄ± Ã¼lkemiz menfaatlerini dÃ¼ÅŸÃ¼nerek iÅŸÃ§i memur haklarÄ±nÄ± tam hakkÄ± \n",
    "ile savunarak mili gÃ¶rÃ¼ÅŸ Ã§atÄ±sÄ± altÄ±nda buluÅŸturdu. Bende milli gÃ¶rÃ¼ÅŸ davasÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±m...\n",
    "\"\"\" \n",
    "\n",
    "prompt = f\"AÅŸaÄŸÄ±daki cÃ¼mleyi anlamÄ±nÄ± koruyarak yeniden ifade et:\\n{input_text}\\nYeniden ifade edilmiÅŸ hali:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=256,\n",
    "    num_return_sequences=1,\n",
    "    temperature=0.6,  # Ã‡Ä±ktÄ± Ã§eÅŸitliliÄŸi\n",
    "    top_p=0.9,        # OlasÄ±lÄ±ÄŸÄ± yÃ¼ksek token'lara odaklanma\n",
    "    do_sample=True,   # Rastgele seÃ§im etkinleÅŸtir\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "augmented_text = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Yeniden ifade edilmiÅŸ hali:\")[-1].strip()\n",
    "\n",
    "print(\"Orijinal Metin:\", input_text)\n",
    "print(\"Augmente EdilmiÅŸ Metin:\", augmented_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:00.964331Z",
     "iopub.status.busy": "2025-01-11T06:49:00.964103Z",
     "iopub.status.idle": "2025-01-11T06:49:02.038592Z",
     "shell.execute_reply": "2025-01-11T06:49:02.037934Z",
     "shell.execute_reply.started": "2025-01-11T06:49:00.964310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "news_dataset = kagglehub.dataset_download('busragural/news-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:02.039466Z",
     "iopub.status.busy": "2025-01-11T06:49:02.039278Z",
     "iopub.status.idle": "2025-01-11T06:49:16.578995Z",
     "shell.execute_reply": "2025-01-11T06:49:16.578087Z",
     "shell.execute_reply.started": "2025-01-11T06:49:02.039448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import time\n",
    "import random\n",
    "from transformers import pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:16.911008Z",
     "iopub.status.busy": "2025-01-11T06:49:16.910705Z",
     "iopub.status.idle": "2025-01-11T06:49:16.966116Z",
     "shell.execute_reply": "2025-01-11T06:49:16.965192Z",
     "shell.execute_reply.started": "2025-01-11T06:49:16.910958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:20.637288Z",
     "iopub.status.busy": "2025-01-11T06:49:20.636958Z",
     "iopub.status.idle": "2025-01-11T06:49:20.642842Z",
     "shell.execute_reply": "2025-01-11T06:49:20.642146Z",
     "shell.execute_reply.started": "2025-01-11T06:49:20.637264Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "!pip install GPUtil\n",
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:20.935559Z",
     "iopub.status.busy": "2025-01-11T06:49:20.935209Z",
     "iopub.status.idle": "2025-01-11T06:49:43.104768Z",
     "shell.execute_reply": "2025-01-11T06:49:43.103896Z",
     "shell.execute_reply.started": "2025-01-11T06:49:20.935525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(news_dataset, '/kaggle/input/news-dataset/interpress_news_category_tr_270k_train.tsv') \n",
    "df = pd.read_csv(dataset_path, sep = '\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:43.106138Z",
     "iopub.status.busy": "2025-01-11T06:49:43.105800Z",
     "iopub.status.idle": "2025-01-11T06:49:43.119755Z",
     "shell.execute_reply": "2025-01-11T06:49:43.118826Z",
     "shell.execute_reply.started": "2025-01-11T06:49:43.106107Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['CategoryCode'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:43.121747Z",
     "iopub.status.busy": "2025-01-11T06:49:43.121516Z",
     "iopub.status.idle": "2025-01-11T06:49:43.198610Z",
     "shell.execute_reply": "2025-01-11T06:49:43.197674Z",
     "shell.execute_reply.started": "2025-01-11T06:49:43.121727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:43.200174Z",
     "iopub.status.busy": "2025-01-11T06:49:43.199878Z",
     "iopub.status.idle": "2025-01-11T06:49:52.675145Z",
     "shell.execute_reply": "2025-01-11T06:49:52.674210Z",
     "shell.execute_reply.started": "2025-01-11T06:49:43.200143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n",
    "\n",
    "def truncate_texts_in_dataframe(df, text_column, tokenizer, max_length=512):\n",
    "    df[text_column] = df[text_column].apply(lambda x: tokenizer.decode(tokenizer(x, truncation=True, max_length=max_length)['input_ids'], skip_special_tokens=True))\n",
    "    return df\n",
    "\n",
    "train_df = df.groupby('CategoryCode').apply(lambda x: x.sample(n=20, random_state=1)).reset_index(drop=True)\n",
    "remaining_df = pd.concat([df, train_df]).drop_duplicates(keep=False)\n",
    "test_df = remaining_df.groupby('CategoryCode').apply(lambda x: x.sample(n=20, random_state=1)).reset_index(drop=True)\n",
    "\n",
    "train_df = truncate_texts_in_dataframe(train_df, 'Content', tokenizer)\n",
    "test_df = truncate_texts_in_dataframe(test_df, 'Content', tokenizer)\n",
    "\n",
    "print(f\"âœ… Train set: {len(train_df)} sample\")\n",
    "print(f\"âœ… Test set: {len(test_df)} sample\")\n",
    "\n",
    "train_df.to_csv(\"trainSet.csv\", index=False)\n",
    "test_df.to_csv(\"testSet.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:52.676487Z",
     "iopub.status.busy": "2025-01-11T06:49:52.676167Z",
     "iopub.status.idle": "2025-01-11T06:49:52.680984Z",
     "shell.execute_reply": "2025-01-11T06:49:52.680126Z",
     "shell.execute_reply.started": "2025-01-11T06:49:52.676455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_models = {\n",
    "    \"minilm\": \"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "    #\"jina\": \"jinaai/jina-embeddings-v3\",\n",
    "    #\"bge\": \"BAAI/bge-m3\"\n",
    "    }\n",
    "classifiers = {\n",
    "    #\"SVM\": SVC(),\n",
    "    #\"RandomForest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=100,   # AÄŸaÃ§ sayÄ±sÄ±\n",
    "        max_depth=6,        # Maksimum derinlik\n",
    "        learning_rate=0.1,  # Ã–ÄŸrenme oranÄ±\n",
    "        subsample=0.8,      # Rastgele Ã¶rnekleme oranÄ±\n",
    "        colsample_bytree=0.8,  # Her aÄŸaÃ§ iÃ§in rastgele Ã¶zellik oranÄ±\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "    #\"MLP\": MLPClassifier(max_iter=500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:52.682113Z",
     "iopub.status.busy": "2025-01-11T06:49:52.681818Z",
     "iopub.status.idle": "2025-01-11T06:49:52.696669Z",
     "shell.execute_reply": "2025-01-11T06:49:52.695813Z",
     "shell.execute_reply.started": "2025-01-11T06:49:52.682085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#rm -rf /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:52.697596Z",
     "iopub.status.busy": "2025-01-11T06:49:52.697359Z",
     "iopub.status.idle": "2025-01-11T06:49:52.714841Z",
     "shell.execute_reply": "2025-01-11T06:49:52.713922Z",
     "shell.execute_reply.started": "2025-01-11T06:49:52.697575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_embeddings(texts, model_name, batch_size=32, max_length=512):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            list(batch_texts),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().type(torch.float32).numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def get_embeddings_and_save(texts, model_name, output_file, batch_size=32):\n",
    "    embeddings = get_embeddings(texts, model_name, batch_size=batch_size)\n",
    "    np.save(output_file, embeddings)\n",
    "    print(f\"Embeddings are saved to {output_file}.\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:49:59.136293Z",
     "iopub.status.busy": "2025-01-11T06:49:59.135921Z",
     "iopub.status.idle": "2025-01-11T06:50:27.398103Z",
     "shell.execute_reply": "2025-01-11T06:50:27.397305Z",
     "shell.execute_reply.started": "2025-01-11T06:49:59.136263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for model_key, model_name in embedding_models.items():\n",
    "    print(f\"\\nCreating embeddings for Model: {model_name}..\")\n",
    "    \n",
    "    model_folder = f\"embeddings/{model_key}\"\n",
    "    os.makedirs(f\"{model_folder}/train\", exist_ok=True)\n",
    "    os.makedirs(f\"{model_folder}/test\", exist_ok=True)\n",
    "    \n",
    "    # Train Embeddings\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        train_embeddings_file = os.path.join(model_folder, \"train\", f\"embeddings_{topic}.npy\")\n",
    "        if not os.path.exists(train_embeddings_file):\n",
    "            topic_texts = train_df[train_df['CategoryCode'] == topic]['Content']\n",
    "            get_embeddings_and_save(topic_texts, model_name, train_embeddings_file)\n",
    "        else:\n",
    "            print(f\"â„¹ï¸ {train_embeddings_file} already existed.\")\n",
    "    \n",
    "    # Test Embeddings\n",
    "    for topic in test_df['CategoryCode'].unique():\n",
    "        test_embeddings_file = os.path.join(model_folder, \"test\", f\"embeddings_{topic}.npy\")\n",
    "        if not os.path.exists(test_embeddings_file):\n",
    "            topic_texts = test_df[test_df['CategoryCode'] == topic]['Content']\n",
    "            get_embeddings_and_save(topic_texts, model_name, test_embeddings_file)\n",
    "        else:\n",
    "            print(f\"â„¹ï¸ {test_embeddings_file} already existed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:50:27.399803Z",
     "iopub.status.busy": "2025-01-11T06:50:27.399489Z",
     "iopub.status.idle": "2025-01-11T06:50:48.698355Z",
     "shell.execute_reply": "2025-01-11T06:50:48.697432Z",
     "shell.execute_reply.started": "2025-01-11T06:50:27.399776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850,680,510,340,170,85]\n",
    "data_sizes = [340, 204,136, 68]\n",
    "test_embeddings = []\n",
    "test_labels = []\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"/kaggle/working/embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    test_embeddings.append(embeddings)\n",
    "    test_labels += [topic] * len(embeddings)\n",
    "\n",
    "test_embeddings = np.vstack(test_embeddings)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Training\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nData size: {size}\")\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(embeddings)\n",
    "        train_labels += [topic] * len(embeddings)\n",
    "    \n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        predictions = clf.predict(test_embeddings)\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "        print(f\"ğŸ”„ {clf_name}: Accuracy={accuracy:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1_score\": f1\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:50:48.700273Z",
     "iopub.status.busy": "2025-01-11T06:50:48.699933Z",
     "iopub.status.idle": "2025-01-11T06:50:49.070476Z",
     "shell.execute_reply": "2025-01-11T06:50:49.069556Z",
     "shell.execute_reply.started": "2025-01-11T06:50:48.700248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_vs_data_size(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for clf_name in classifiers.keys():\n",
    "        accuracies = []\n",
    "        for size in data_sizes:\n",
    "            clf_result = next((res for res in results[size] if res['classifier'] == clf_name), None)\n",
    "            if clf_result:\n",
    "                accuracies.append(clf_result['accuracy'])\n",
    "            else:\n",
    "                accuracies.append(None)\n",
    "        \n",
    "        plt.plot(data_sizes, accuracies, marker='o', linestyle='-', label=f\"{clf_name}\")\n",
    "        \n",
    "        for i, acc in enumerate(accuracies):\n",
    "            if acc is not None:\n",
    "                plt.text(data_sizes[i], acc, f\"{acc:.2f}\", \n",
    "                         fontsize=8, color='black', ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Effect of Training Dataset Sizes on Test Accuracy')\n",
    "    plt.xlabel('Dataset Size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(data_sizes)\n",
    "    plt.legend(title='Classifiers')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy_vs_data_size(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:13.302854Z",
     "iopub.status.busy": "2025-01-11T06:11:13.302566Z",
     "iopub.status.idle": "2025-01-11T06:11:13.344468Z",
     "shell.execute_reply": "2025-01-11T06:11:13.343574Z",
     "shell.execute_reply.started": "2025-01-11T06:11:13.302833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# DBMDZ BERT Pipeline\n",
    "mask_filler = pipeline(\"fill-mask\", model=\"dbmdz/bert-base-turkish-cased\", device=device)\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "def augment_text_with_berturk(text, num_variations=3, max_length=512):\n",
    "    augmented_texts = set()\n",
    "    tokenizer = mask_filler.tokenizer  # Mask filler'dan tokenizer alÄ±n\n",
    "    text = truncate_text(text, tokenizer, max_length=max_length)  # Metni kÄ±salt\n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        words = text.split() \n",
    "        x = max(1, len(words))\n",
    "\n",
    "        for i in range(x):\n",
    "            masked_text = words.copy()\n",
    "            mask_index = random.randint(0, len(masked_text) - 1)\n",
    "            masked_text[mask_index] = \"[MASK]\"\n",
    "            masked_sentence = \" \".join(masked_text)\n",
    "            \n",
    "            # Uzunluk kontrolÃ¼\n",
    "            if len(tokenizer(masked_sentence)['input_ids']) > 512:\n",
    "                print(\"âš ï¸ Masked sentence too long, skipping:\", masked_sentence)\n",
    "                continue\n",
    "\n",
    "            \n",
    "            predictions = mask_filler(masked_sentence)\n",
    "            if isinstance(predictions, list) and len(predictions) > 0:\n",
    "                pred = predictions[0]  # Ä°lk tahmini al\n",
    "                if isinstance(pred, dict):\n",
    "                    token_str = pred.get('token_str', '').strip()\n",
    "                    if token_str:\n",
    "                        words[mask_index] = token_str\n",
    "            else:\n",
    "                print(\"âš ï¸ Beklenmeyen Ã§Ä±ktÄ± formatÄ±:\", predictions)\n",
    "                break\n",
    "        \n",
    "        new_text = \" \".join(words)\n",
    "        augmented_texts.add(new_text)\n",
    "    \n",
    "    return list(augmented_texts)\n",
    "def truncate_text(text, tokenizer, max_length=512):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) > max_length:\n",
    "        truncated_tokens = tokens[:max_length]\n",
    "        truncated_text = tokenizer.convert_tokens_to_string(truncated_tokens)\n",
    "        return truncated_text\n",
    "    return text\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:13.345533Z",
     "iopub.status.busy": "2025-01-11T06:11:13.345256Z",
     "iopub.status.idle": "2025-01-11T06:11:13.360988Z",
     "shell.execute_reply": "2025-01-11T06:11:13.360244Z",
     "shell.execute_reply.started": "2025-01-11T06:11:13.345499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def majority_voting(original_pred, aug_preds):\n",
    "    votes = aug_preds + [original_pred]\n",
    "    return max(set(votes), key=votes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:13.362193Z",
     "iopub.status.busy": "2025-01-11T06:11:13.361913Z",
     "iopub.status.idle": "2025-01-11T06:11:17.959424Z",
     "shell.execute_reply": "2025-01-11T06:11:17.958421Z",
     "shell.execute_reply.started": "2025-01-11T06:11:13.362164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import random\n",
    "\n",
    "def lowercase_turkish(text):\n",
    "    \"\"\"\n",
    "    Converts text to lowercase for Turkish language, handling special case for 'I'.\n",
    "    \"\"\"\n",
    "    return text.replace(\"I\", \"Ä±\").lower()\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "mask_filler = pipeline(\"fill-mask\", model=\"ytu-ce-cosmos/turkish-base-bert-uncased\", device=device)\n",
    "\n",
    "def augment_text_with_berturk(text, num_variations=3, max_length=512):\n",
    "    augmented_texts = set()\n",
    "    tokenizer = mask_filler.tokenizer \n",
    "    text = lowercase_turkish(text)  \n",
    "    text = truncate_text(text, tokenizer, max_length=max_length)  \n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        words = text.split() \n",
    "        x = max(1, len(words)// 3)\n",
    "\n",
    "        for i in range(x):\n",
    "            masked_text = words.copy()\n",
    "            mask_index = random.randint(0, len(masked_text) - 1)\n",
    "            masked_text[mask_index] = \"[MASK]\"\n",
    "            masked_sentence = \" \".join(masked_text)\n",
    "            \n",
    "            if len(tokenizer(masked_sentence)['input_ids']) > 512:\n",
    "                print(\"âš ï¸ Masked sentence too long, skipping:\", masked_sentence)\n",
    "                continue\n",
    "\n",
    "            predictions = mask_filler(masked_sentence)\n",
    "            if isinstance(predictions, list) and len(predictions) > 0:\n",
    "                pred = predictions[0]  \n",
    "                if isinstance(pred, dict):\n",
    "                    token_str = pred.get('token_str', '').strip()\n",
    "                    if token_str:\n",
    "                        words[mask_index] = token_str\n",
    "            else:\n",
    "                print(\"âš ï¸ Beklenmeyen Ã§Ä±ktÄ± formatÄ±:\", predictions)\n",
    "                break\n",
    "        \n",
    "        new_text = \" \".join(words)\n",
    "        augmented_texts.add(new_text)\n",
    "    \n",
    "    return list(augmented_texts)\n",
    "\n",
    "def truncate_text(text, tokenizer, max_length=512):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    if len(tokens) > max_length:\n",
    "        truncated_tokens = tokens[:max_length]\n",
    "        truncated_text = tokenizer.convert_tokens_to_string(truncated_tokens)\n",
    "        return truncated_text\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-10T21:16:37.264738Z",
     "iopub.status.idle": "2025-01-10T21:16:37.265006Z",
     "shell.execute_reply": "2025-01-10T21:16:37.264898Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_3 = augment_text_with_berturk(text, num_variations=3)\n",
    "        print(\"3 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/bert/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Augmented texts saved to {aug_texts_3_file}.\")\n",
    "\n",
    "        aug_embeddings_3 = get_embeddings(aug_texts_3, embedding_models['minilm'])\n",
    "        print(\"Yeni 3 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Augmented embeddings saved to {aug_embeddings_3_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-09T18:13:17.144063Z",
     "iopub.status.busy": "2025-01-09T18:13:17.143809Z",
     "iopub.status.idle": "2025-01-09T18:22:37.486263Z",
     "shell.execute_reply": "2025-01-09T18:22:37.485339Z",
     "shell.execute_reply.started": "2025-01-09T18:13:17.144042Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_berturk(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/bert/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "\n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"Yeni 5 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:11:17.960631Z",
     "iopub.status.busy": "2025-01-11T06:11:17.960326Z",
     "iopub.status.idle": "2025-01-11T06:25:44.163178Z",
     "shell.execute_reply": "2025-01-11T06:25:44.162312Z",
     "shell.execute_reply.started": "2025-01-11T06:11:17.960609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    \n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_berturk(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/bert/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "        \n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"5 Embedding oluÅŸturuldu.\")\n",
    "        \n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")\n",
    "        \n",
    "        selected_indices = random.sample(range(5), 3)\n",
    "        aug_texts_3 = [aug_texts_5[i] for i in selected_indices]\n",
    "        aug_embeddings_3 = [aug_embeddings_5[i] for i in selected_indices]\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/bert/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)  \n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Selected augmented texts saved to {aug_texts_3_file}.\")\n",
    "        \n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)  \n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Selected augmented embeddings saved to {aug_embeddings_3_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:25:44.164589Z",
     "iopub.status.busy": "2025-01-11T06:25:44.164244Z",
     "iopub.status.idle": "2025-01-11T06:26:05.775103Z",
     "shell.execute_reply": "2025-01-11T06:26:05.774266Z",
     "shell.execute_reply.started": "2025-01-11T06:25:44.164555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"ğŸ”„ {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_5 = []\n",
    "        augmented_test_predictions_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_5_file = f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_5 = np.load(aug_embeddings_5_file)\n",
    "\n",
    "                aug_embeddings_3_file = f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_3 = np.load(aug_embeddings_3_file)\n",
    "\n",
    "                aug_preds_5 = clf.predict(aug_embeddings_5)\n",
    "\n",
    "                aug_preds_3 = clf.predict(aug_embeddings_3)\n",
    "\n",
    "                final_pred_5 = majority_voting(original_pred, aug_preds_5.tolist())\n",
    "                augmented_test_predictions_5.append(final_pred_5)\n",
    "\n",
    "                final_pred_3 = majority_voting(original_pred, aug_preds_3.tolist())\n",
    "                augmented_test_predictions_3.append(final_pred_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_5 = accuracy_score(test_labels, augmented_test_predictions_5)\n",
    "        augmented_accuracy_3 = accuracy_score(test_labels, augmented_test_predictions_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_5\": augmented_accuracy_5,\n",
    "            \"augmented_accuracy_3\": augmented_accuracy_3\n",
    "        })\n",
    "        print(f\"âœ… {clf_name} - Original Accuracy: {original_accuracy:.4f}, Augmented Accuracy (5): {augmented_accuracy_5:.4f}, Augmented Accuracy (3): {augmented_accuracy_3:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_5 = [next((res['augmented_accuracy_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_3 = [next((res['augmented_accuracy_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_5, marker='x', linestyle='--', label=f\"{clf_name} - Augmented (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_3, marker='s', linestyle='-.', label=f\"{clf_name} - Augmented (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:26:05.776481Z",
     "iopub.status.busy": "2025-01-11T06:26:05.776124Z",
     "iopub.status.idle": "2025-01-11T06:26:11.038281Z",
     "shell.execute_reply": "2025-01-11T06:26:11.037368Z",
     "shell.execute_reply.started": "2025-01-11T06:26:05.776449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:26:11.039620Z",
     "iopub.status.busy": "2025-01-11T06:26:11.039357Z",
     "iopub.status.idle": "2025-01-11T06:26:11.389485Z",
     "shell.execute_reply": "2025-01-11T06:26:11.388717Z",
     "shell.execute_reply.started": "2025-01-11T06:26:11.039598Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###llama3-8b-8192\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "GROQ_API_KEY = \"\"\n",
    "\n",
    "def augment_text_with_llama(text, num_variations=3):\n",
    "    client = Groq(api_key=GROQ_API_KEY)\n",
    "    augmented_texts = set()\n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        try:\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Bu metni anlamÄ±nÄ± kaybetmeden yeniden TÃ¼rkÃ§e yaz ve yalnÄ±zca yeni metni yaz: {text}\",\n",
    "                    }\n",
    "                ],\n",
    "                model=\"llama3-8b-8192\",\n",
    "            )\n",
    "            generated_text = chat_completion.choices[0].message.content.strip()\n",
    "            augmented_texts.add(generated_text)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error during augmentation: {e}\")\n",
    "\n",
    "    return list(augmented_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-09T19:56:12.452221Z",
     "iopub.status.idle": "2025-01-09T19:56:12.452447Z",
     "shell.execute_reply": "2025-01-09T19:56:12.452351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "aug_texts_3 = augment_text_with_llama(test_df.iloc[0]['Content'], num_variations=3)\n",
    "aug_texts_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-09T17:34:47.218368Z",
     "iopub.status.busy": "2025-01-09T17:34:47.218075Z",
     "iopub.status.idle": "2025-01-09T17:36:07.878275Z",
     "shell.execute_reply": "2025-01-09T17:36:07.877272Z",
     "shell.execute_reply.started": "2025-01-09T17:34:47.218346Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_3 = augment_text_with_llama(text, num_variations=3)\n",
    "        print(\"3 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/llama/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Augmented texts saved to {aug_texts_3_file}.\")\n",
    "\n",
    "        aug_embeddings_3 = get_embeddings(aug_texts_3, embedding_models['minilm'])\n",
    "        print(\"Yeni 3 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Augmented embeddings saved to {aug_embeddings_3_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-01-09T17:36:26.071690Z",
     "iopub.status.busy": "2025-01-09T17:36:26.071344Z",
     "iopub.status.idle": "2025-01-09T17:39:52.239193Z",
     "shell.execute_reply": "2025-01-09T17:39:52.238377Z",
     "shell.execute_reply.started": "2025-01-09T17:36:26.071662Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_llama(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/llama/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "\n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"Yeni 5 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:26:11.392468Z",
     "iopub.status.busy": "2025-01-11T06:26:11.392182Z",
     "iopub.status.idle": "2025-01-11T06:32:24.243395Z",
     "shell.execute_reply": "2025-01-11T06:32:24.242476Z",
     "shell.execute_reply.started": "2025-01-11T06:26:11.392443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    \n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_llama(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/llama/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "        \n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"5 Embedding oluÅŸturuldu.\")\n",
    "        \n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")\n",
    "        \n",
    "        selected_indices = random.sample(range(5), 3)\n",
    "        aug_texts_3 = [aug_texts_5[i] for i in selected_indices]\n",
    "        aug_embeddings_3 = [aug_embeddings_5[i] for i in selected_indices]\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/llama/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True) \n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Selected augmented texts saved to {aug_texts_3_file}.\")\n",
    "        \n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)  \n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Selected augmented embeddings saved to {aug_embeddings_3_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:32:24.245109Z",
     "iopub.status.busy": "2025-01-11T06:32:24.244761Z",
     "iopub.status.idle": "2025-01-11T06:32:45.429084Z",
     "shell.execute_reply": "2025-01-11T06:32:45.428202Z",
     "shell.execute_reply.started": "2025-01-11T06:32:24.245071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"ğŸ”„ {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_5 = []\n",
    "        augmented_test_predictions_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_5_file = f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_5 = np.load(aug_embeddings_5_file)\n",
    "\n",
    "                aug_embeddings_3_file = f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_3 = np.load(aug_embeddings_3_file)\n",
    "\n",
    "                aug_preds_5 = clf.predict(aug_embeddings_5)\n",
    "\n",
    "                aug_preds_3 = clf.predict(aug_embeddings_3)\n",
    "\n",
    "                final_pred_5 = majority_voting(original_pred, aug_preds_5.tolist())\n",
    "                augmented_test_predictions_5.append(final_pred_5)\n",
    "\n",
    "                final_pred_3 = majority_voting(original_pred, aug_preds_3.tolist())\n",
    "                augmented_test_predictions_3.append(final_pred_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_5 = accuracy_score(test_labels, augmented_test_predictions_5)\n",
    "        augmented_accuracy_3 = accuracy_score(test_labels, augmented_test_predictions_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_5\": augmented_accuracy_5,\n",
    "            \"augmented_accuracy_3\": augmented_accuracy_3\n",
    "        })\n",
    "        print(f\"âœ… {clf_name} - Original Accuracy: {original_accuracy:.4f}, Augmented Accuracy (5): {augmented_accuracy_5:.4f}, Augmented Accuracy (3): {augmented_accuracy_3:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_5 = [next((res['augmented_accuracy_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_3 = [next((res['augmented_accuracy_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_5, marker='x', linestyle='--', label=f\"{clf_name} - Augmented (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_3, marker='s', linestyle='-.', label=f\"{clf_name} - Augmented (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:46:51.102524Z",
     "iopub.status.busy": "2025-01-09T17:46:51.102198Z",
     "iopub.status.idle": "2025-01-09T17:47:27.629330Z",
     "shell.execute_reply": "2025-01-09T17:47:27.628422Z",
     "shell.execute_reply.started": "2025-01-09T17:46:51.102500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name=\"ytu-ce-cosmos/turkish-gpt2-large\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    " # GPU desteÄŸi varsa modele taÅŸÄ±\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def augment_text_with_gpt2(input_text, num_variations=3 ):\n",
    "    augmented_texts = set()\n",
    "\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        # Augmentation iÃ§in prompt hazÄ±rla\n",
    "        prompt = f\"AÅŸaÄŸÄ±daki cÃ¼mleyi anlamÄ±nÄ± koruyarak yeniden ifade et:\\n{input_text}\\nYeniden ifade edilmiÅŸ hali:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Modelden Ã§Ä±ktÄ± Ã¼ret\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        # Ã‡Ä±ktÄ±yÄ± Ã§Ã¶zÃ¼mle ve ekle\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Yeniden ifade edilmiÅŸ hali:\")[-1].strip()\n",
    "        augmented_texts.add(generated_text)\n",
    "\n",
    "    return list(augmented_texts)\n",
    "        \n",
    "\n",
    "# Ã–rnek kullanÄ±m\n",
    "original_text = \"\"\"\n",
    "AyakÃ¼stÃ¼ Ã¼ye kazandÄ±lar Saadet Partisi il BaÅŸkan YardÄ±mcÄ±sÄ± Salih Kocatepe, \n",
    "iznik te esnaf ziyareti sÄ±rasÄ±nda iznik esnaflarÄ±ndan partiye Ã¼ye olmak isteyen \n",
    "Osman YÄ±ldÄ±z adlÄ± vatandaÅŸa kendi rozetini Ã§Ä±kartarak taktÄ±. Ãœye olan Osman YÄ±ldÄ±z \n",
    "Saadet Partisini yakÄ±ndan takip ediyorum. Geriye dÃ¶nÃ¼k Rahmetli Erbakan Hocaya duyduÄŸum \n",
    "sevgi ve saygÄ±mdan dolayÄ± Ã¼lkemiz menfaatlerini dÃ¼ÅŸÃ¼nerek iÅŸÃ§i memur haklarÄ±nÄ± tam hakkÄ± \n",
    "ile savunarak mili gÃ¶rÃ¼ÅŸ Ã§atÄ±sÄ± altÄ±nda buluÅŸturdu. Bende milli gÃ¶rÃ¼ÅŸ davasÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±m...\n",
    "\"\"\"\n",
    "\n",
    "augmented_texts = augment_text_with_gpt2(original_text, num_variations=3)\n",
    "for idx, text in enumerate(augmented_texts, start=1):\n",
    "    print(f\"Varyasyon {idx}: {text}\\n\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:47:48.802896Z",
     "iopub.status.busy": "2025-01-09T17:47:48.802582Z",
     "iopub.status.idle": "2025-01-09T17:48:23.798528Z",
     "shell.execute_reply": "2025-01-09T17:48:23.797741Z",
     "shell.execute_reply.started": "2025-01-09T17:47:48.802872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "aug_texts_3 = augment_text_with_gpt2(test_df.iloc[0]['Content'], num_variations=3)\n",
    "aug_texts_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:32:45.430143Z",
     "iopub.status.busy": "2025-01-11T06:32:45.429907Z",
     "iopub.status.idle": "2025-01-11T06:33:24.653524Z",
     "shell.execute_reply": "2025-01-11T06:33:24.652624Z",
     "shell.execute_reply.started": "2025-01-11T06:32:45.430123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"ytu-ce-cosmos/turkish-gpt2-medium-350m-instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def augment_text_with_gpt2(input_text, num_variations=3):\n",
    "    augmented_texts = set()\n",
    "    max_length = model.config.max_position_embeddings\n",
    "    while len(augmented_texts) < num_variations:\n",
    "        prompt = f\"AÅŸaÄŸÄ±daki cÃ¼mleyi anlamÄ±nÄ± koruyarak yeniden ifade et:\\n{input_text}\\nYeniden ifade edilmiÅŸ hali:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Yeniden ifade edilmiÅŸ hali:\")[-1].strip()\n",
    "        augmented_texts.add(generated_text)\n",
    "\n",
    "    return list(augmented_texts)\n",
    "\n",
    "aug_texts_3 = augment_text_with_gpt2(test_df.iloc[2]['Content'], num_variations=3)\n",
    "aug_texts_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:54:13.133203Z",
     "iopub.status.busy": "2025-01-09T17:54:13.132841Z",
     "iopub.status.idle": "2025-01-09T17:56:16.411399Z",
     "shell.execute_reply": "2025-01-09T17:56:16.410518Z",
     "shell.execute_reply.started": "2025-01-09T17:54:13.133174Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_3 = augment_text_with_gpt2(text, num_variations=3)\n",
    "        print(\"3 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/gpt2/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Augmented texts saved to {aug_texts_3_file}.\")\n",
    "\n",
    "        aug_embeddings_3 = get_embeddings(aug_texts_3, embedding_models['minilm'])\n",
    "        print(\"Yeni 3 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Augmented embeddings saved to {aug_embeddings_3_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T17:56:27.417588Z",
     "iopub.status.busy": "2025-01-09T17:56:27.417285Z",
     "iopub.status.idle": "2025-01-09T17:59:09.163794Z",
     "shell.execute_reply": "2025-01-09T17:59:09.162868Z",
     "shell.execute_reply.started": "2025-01-09T17:56:27.417564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_gpt2(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/gpt2/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "\n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"Yeni 5 embeddingler.\")\n",
    "\n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:33:24.654563Z",
     "iopub.status.busy": "2025-01-11T06:33:24.654310Z",
     "iopub.status.idle": "2025-01-11T06:36:41.675753Z",
     "shell.execute_reply": "2025-01-11T06:36:41.674963Z",
     "shell.execute_reply.started": "2025-01-11T06:33:24.654542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "for topic in test_df['CategoryCode'].unique():\n",
    "    embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "    texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "    \n",
    "    for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        aug_texts_5 = augment_text_with_gpt2(text, num_variations=5)\n",
    "        print(\"5 Augmentation yapÄ±ldÄ±.\")\n",
    "        \n",
    "        aug_texts_5_file = f\"augmented_texts/gpt2/5/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_5_file), exist_ok=True)\n",
    "        np.save(aug_texts_5_file, aug_texts_5)\n",
    "        print(f\"5 Augmented texts saved to {aug_texts_5_file}.\")\n",
    "        \n",
    "        aug_embeddings_5 = get_embeddings(aug_texts_5, embedding_models['minilm'])\n",
    "        print(\"5 Embedding oluÅŸturuldu.\")\n",
    "        \n",
    "        aug_embeddings_5_file = f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_5_file), exist_ok=True)\n",
    "        np.save(aug_embeddings_5_file, aug_embeddings_5)\n",
    "        print(f\"5 Augmented embeddings saved to {aug_embeddings_5_file}.\")\n",
    "        \n",
    "        selected_indices = random.sample(range(5), 3)\n",
    "        aug_texts_3 = [aug_texts_5[i] for i in selected_indices]\n",
    "        aug_embeddings_3 = [aug_embeddings_5[i] for i in selected_indices]\n",
    "        \n",
    "        aug_texts_3_file = f\"augmented_texts/gpt2/3/{topic}_text_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_texts_3_file), exist_ok=True)  # Dizini oluÅŸtur\n",
    "        np.save(aug_texts_3_file, aug_texts_3)\n",
    "        print(f\"3 Selected augmented texts saved to {aug_texts_3_file}.\")\n",
    "        \n",
    "        aug_embeddings_3_file = f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\"\n",
    "        os.makedirs(os.path.dirname(aug_embeddings_3_file), exist_ok=True)  # Dizini oluÅŸtur\n",
    "        np.save(aug_embeddings_3_file, aug_embeddings_3)\n",
    "        print(f\"3 Selected augmented embeddings saved to {aug_embeddings_3_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:36:41.676861Z",
     "iopub.status.busy": "2025-01-11T06:36:41.676605Z",
     "iopub.status.idle": "2025-01-11T06:37:03.069298Z",
     "shell.execute_reply": "2025-01-11T06:37:03.068455Z",
     "shell.execute_reply.started": "2025-01-11T06:36:41.676839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Train classifiers\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"ğŸ”„ {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_5 = []\n",
    "        augmented_test_predictions_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_5_file = f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_5 = np.load(aug_embeddings_5_file)\n",
    "\n",
    "                aug_embeddings_3_file = f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\"\n",
    "                aug_embeddings_3 = np.load(aug_embeddings_3_file)\n",
    "\n",
    "                aug_preds_5 = clf.predict(aug_embeddings_5)\n",
    "\n",
    "                aug_preds_3 = clf.predict(aug_embeddings_3)\n",
    "\n",
    "                final_pred_5 = majority_voting(original_pred, aug_preds_5.tolist())\n",
    "                augmented_test_predictions_5.append(final_pred_5)\n",
    "\n",
    "                final_pred_3 = majority_voting(original_pred, aug_preds_3.tolist())\n",
    "                augmented_test_predictions_3.append(final_pred_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_5 = accuracy_score(test_labels, augmented_test_predictions_5)\n",
    "        augmented_accuracy_3 = accuracy_score(test_labels, augmented_test_predictions_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_5\": augmented_accuracy_5,\n",
    "            \"augmented_accuracy_3\": augmented_accuracy_3\n",
    "        })\n",
    "        print(f\"âœ… {clf_name} - Original Accuracy: {original_accuracy:.4f}, Augmented Accuracy (5): {augmented_accuracy_5:.4f}, Augmented Accuracy (3): {augmented_accuracy_3:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_5 = [next((res['augmented_accuracy_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_3 = [next((res['augmented_accuracy_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_5, marker='x', linestyle='--', label=f\"{clf_name} - Augmented (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_3, marker='s', linestyle='-.', label=f\"{clf_name} - Augmented (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T06:37:03.070669Z",
     "iopub.status.busy": "2025-01-11T06:37:03.070425Z",
     "iopub.status.idle": "2025-01-11T06:37:24.235264Z",
     "shell.execute_reply": "2025-01-11T06:37:24.234452Z",
     "shell.execute_reply.started": "2025-01-11T06:37:03.070646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#data_sizes = [850, 680, 510, 340, 170, 85]\n",
    "\n",
    "results = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\nTraining models with data size: {size}\")\n",
    "\n",
    "    # Prepare training data\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"ğŸ”„ {clf_name} trained with data size {size}.\")\n",
    "\n",
    "        original_test_predictions = []\n",
    "        augmented_test_predictions_bert_5 = []\n",
    "        augmented_test_predictions_bert_3 = []\n",
    "        augmented_test_predictions_llama_5 = []\n",
    "        augmented_test_predictions_llama_3 = []\n",
    "        augmented_test_predictions_gpt2_5 = []\n",
    "        augmented_test_predictions_gpt2_3 = []\n",
    "\n",
    "        for topic in test_df['CategoryCode'].unique():\n",
    "            embeddings = np.load(f\"embeddings/minilm/test/embeddings_{topic}.npy\")\n",
    "            texts = test_df[test_df['CategoryCode'] == topic]['Content'].tolist()\n",
    "            for idx, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "                original_pred = clf.predict([embedding])[0]\n",
    "                original_test_predictions.append(original_pred)\n",
    "\n",
    "                aug_embeddings_bert_5 = np.load(f\"augmented_embeddings/bert/5/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_llama_5 = np.load(f\"augmented_embeddings/llama/5/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_gpt2_5 = np.load(f\"augmented_embeddings/gpt2/5/{topic}_embedding_{idx}.npy\")\n",
    "\n",
    "                aug_embeddings_bert_3 = np.load(f\"augmented_embeddings/bert/3/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_llama_3 = np.load(f\"augmented_embeddings/llama/3/{topic}_embedding_{idx}.npy\")\n",
    "                aug_embeddings_gpt2_3 = np.load(f\"augmented_embeddings/gpt2/3/{topic}_embedding_{idx}.npy\")\n",
    "\n",
    "                aug_preds_bert_5 = clf.predict(aug_embeddings_bert_5)\n",
    "                aug_preds_bert_3 = clf.predict(aug_embeddings_bert_3)\n",
    "\n",
    "                aug_preds_llama_5 = clf.predict(aug_embeddings_llama_5)\n",
    "                aug_preds_llama_3 = clf.predict(aug_embeddings_llama_3)\n",
    "\n",
    "                aug_preds_gpt2_5 = clf.predict(aug_embeddings_gpt2_5)\n",
    "                aug_preds_gpt2_3 = clf.predict(aug_embeddings_gpt2_3)\n",
    "\n",
    "                final_pred_bert_5 = majority_voting(original_pred, aug_preds_bert_5.tolist())\n",
    "                final_pred_bert_3 = majority_voting(original_pred, aug_preds_bert_3.tolist())\n",
    "                final_pred_llama_5 = majority_voting(original_pred, aug_preds_llama_5.tolist())\n",
    "                final_pred_llama_3 = majority_voting(original_pred, aug_preds_llama_3.tolist())\n",
    "                final_pred_gpt2_5 = majority_voting(original_pred, aug_preds_gpt2_5.tolist())\n",
    "                final_pred_gpt2_3 = majority_voting(original_pred, aug_preds_gpt2_3.tolist())\n",
    "\n",
    "                augmented_test_predictions_bert_5.append(final_pred_bert_5)\n",
    "                augmented_test_predictions_bert_3.append(final_pred_bert_3)\n",
    "                augmented_test_predictions_llama_5.append(final_pred_llama_5)\n",
    "                augmented_test_predictions_llama_3.append(final_pred_llama_3)\n",
    "                augmented_test_predictions_gpt2_5.append(final_pred_gpt2_5)\n",
    "                augmented_test_predictions_gpt2_3.append(final_pred_gpt2_3)\n",
    "\n",
    "        original_accuracy = accuracy_score(test_labels, original_test_predictions)\n",
    "        augmented_accuracy_bert_5 = accuracy_score(test_labels, augmented_test_predictions_bert_5)\n",
    "        augmented_accuracy_bert_3 = accuracy_score(test_labels, augmented_test_predictions_bert_3)\n",
    "        augmented_accuracy_llama_5 = accuracy_score(test_labels, augmented_test_predictions_llama_5)\n",
    "        augmented_accuracy_llama_3 = accuracy_score(test_labels, augmented_test_predictions_llama_3)\n",
    "        augmented_accuracy_gpt2_5 = accuracy_score(test_labels, augmented_test_predictions_gpt2_5)\n",
    "        augmented_accuracy_gpt2_3 = accuracy_score(test_labels, augmented_test_predictions_gpt2_3)\n",
    "\n",
    "        results[size].append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"original_accuracy\": original_accuracy,\n",
    "            \"augmented_accuracy_bert_5\": augmented_accuracy_bert_5,\n",
    "            \"augmented_accuracy_bert_3\": augmented_accuracy_bert_3,\n",
    "            \"augmented_accuracy_llama_5\": augmented_accuracy_llama_5,\n",
    "            \"augmented_accuracy_llama_3\": augmented_accuracy_llama_3,\n",
    "            \"augmented_accuracy_gpt2_5\": augmented_accuracy_gpt2_5,\n",
    "            \"augmented_accuracy_gpt2_3\": augmented_accuracy_gpt2_3\n",
    "        })\n",
    "        print(f\"âœ… {clf_name} - Original Accuracy: {original_accuracy:.4f}, BERT-5: {augmented_accuracy_bert_5:.4f}, BERT-3: {augmented_accuracy_bert_3:.4f}, LLama-5: {augmented_accuracy_llama_5:.4f}, LLama-3: {augmented_accuracy_llama_3:.4f}, GPT2-5: {augmented_accuracy_gpt2_5:.4f}, GPT2-3: {augmented_accuracy_gpt2_3:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(14, 10))\n",
    "for clf_name in classifiers.keys():\n",
    "    original_accuracies = [next((res['original_accuracy'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_bert_5 = [next((res['augmented_accuracy_bert_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_bert_3 = [next((res['augmented_accuracy_bert_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_llama_5 = [next((res['augmented_accuracy_llama_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_llama_3 = [next((res['augmented_accuracy_llama_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_gpt2_5 = [next((res['augmented_accuracy_gpt2_5'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "    augmented_accuracies_gpt2_3 = [next((res['augmented_accuracy_gpt2_3'] for res in results[size] if res['classifier'] == clf_name), None) for size in data_sizes]\n",
    "\n",
    "    plt.plot(data_sizes, original_accuracies, marker='o', linestyle='-', label=f\"{clf_name} - Original\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_bert_5, marker='x', linestyle='--', label=f\"{clf_name} - BERT (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_bert_3, marker='s', linestyle='--', label=f\"{clf_name} - BERT (3)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_llama_5, marker='^', linestyle='-.', label=f\"{clf_name} - LLama (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_llama_3, marker='v', linestyle='-.', label=f\"{clf_name} - LLama (3)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_gpt2_5, marker='d', linestyle=':', label=f\"{clf_name} - GPT-2 (5)\")\n",
    "    plt.plot(data_sizes, augmented_accuracies_gpt2_3, marker='p', linestyle=':', label=f\"{clf_name} - GPT-2 (3)\")\n",
    "\n",
    "plt.title('Performance Comparison: Original vs Augmented Data')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(data_sizes)\n",
    "plt.legend(title='Classifiers', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T18:43:01.661848Z",
     "iopub.status.busy": "2025-01-09T18:43:01.661532Z",
     "iopub.status.idle": "2025-01-09T18:43:21.852581Z",
     "shell.execute_reply": "2025-01-09T18:43:21.851837Z",
     "shell.execute_reply.started": "2025-01-09T18:43:01.661826Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_example = test_df.iloc[0]['Content']\n",
    "print(f\"Original Test Example: {test_example}\\n\")\n",
    "\n",
    "augmented_texts = augment_text_with_berturk(test_example, num_variations=3)\n",
    "print(\"Augmented Examples:\")\n",
    "for idx, text in enumerate(augmented_texts, start=1):\n",
    "    print(f\"  Augmented {idx}: {text}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for size in data_sizes:\n",
    "    print(f\"\\n=== Training with data size: {size} ===\")\n",
    "\n",
    "    train_embeddings = []\n",
    "    train_labels = []\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_embeddings = np.load(f\"embeddings/minilm/train/embeddings_{topic}.npy\")[:size // len(train_df['CategoryCode'].unique())]\n",
    "        train_embeddings.append(topic_embeddings)\n",
    "        train_labels += [topic] * len(topic_embeddings)\n",
    "\n",
    "    train_embeddings = np.vstack(train_embeddings)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        clf.fit(train_embeddings, train_labels)\n",
    "        print(f\"  ğŸ”„ {clf_name} trained.\")\n",
    "\n",
    "        original_embedding = np.load(f\"embeddings/minilm/test/embeddings_{test_df.iloc[0]['CategoryCode']}.npy\")[0].reshape(1, -1)\n",
    "        original_prediction = clf.predict(original_embedding)[0]\n",
    "        print(f\"  {clf_name} - Original Prediction: {original_prediction}\")\n",
    "\n",
    "        augmented_embeddings = get_embeddings(augmented_texts, embedding_models['minilm'])\n",
    "        augmented_predictions = clf.predict(augmented_embeddings)\n",
    "        for idx, pred in enumerate(augmented_predictions, start=1):\n",
    "            print(f\"  {clf_name} - Augmented {idx} Prediction: {pred}\")\n",
    "\n",
    "        all_predictions = [original_prediction] + augmented_predictions.tolist()\n",
    "        final_prediction = max(set(all_predictions), key=all_predictions.count)\n",
    "        print(f\"  {clf_name} - Final Prediction (Majority Voting): {final_prediction}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:41:17.458316Z",
     "iopub.status.busy": "2025-01-10T20:41:17.458014Z",
     "iopub.status.idle": "2025-01-10T20:53:40.570963Z",
     "shell.execute_reply": "2025-01-10T20:53:40.569438Z",
     "shell.execute_reply.started": "2025-01-10T20:41:17.458293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def augment_training_data(train_texts, num_variations=4):\n",
    "    augmented_texts = []\n",
    "    for text in tqdm(train_texts, desc=\"Augmenting training data\"):\n",
    "        augmented_variations = augment_text_with_llama(text, num_variations=num_variations)\n",
    "        augmented_texts.extend(augmented_variations)\n",
    "    return augmented_texts\n",
    "\n",
    "def process_and_save_augmented_data(train_df, output_dir, model_name, num_variations=4):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for topic in train_df['CategoryCode'].unique():\n",
    "        topic_texts = train_df[train_df['CategoryCode'] == topic]['Content']\n",
    "        \n",
    "        augmented_file = os.path.join(output_dir, f\"augmented_texts_{topic}.npy\")\n",
    "        if os.path.exists(augmented_file):\n",
    "            print(f\"â„¹ï¸ Augmented texts already exist: {augmented_file}\")\n",
    "            augmented_texts = np.load(augmented_file, allow_pickle=True).tolist()\n",
    "        else:\n",
    "            augmented_texts = augment_training_data(topic_texts, num_variations=num_variations)\n",
    "            np.save(augmented_file, np.array(augmented_texts, dtype=object))\n",
    "            print(f\"âœ… Augmented texts saved: {augmented_file}\")\n",
    "\n",
    "        embeddings_file = os.path.join(output_dir, f\"embeddings_{topic}.npy\")\n",
    "        if os.path.exists(embeddings_file):\n",
    "            print(f\"â„¹ï¸ Embeddings already exist: {embeddings_file}\")\n",
    "        else:\n",
    "            embeddings = get_embeddings(augmented_texts, model_name)\n",
    "            np.save(embeddings_file, embeddings)\n",
    "            print(f\"âœ… Embeddings saved: {embeddings_file}\")\n",
    "\n",
    "train_texts = train_df['Content']\n",
    "augment_output_dir = \"augmented_data/llama\"\n",
    "process_and_save_augmented_data(train_df, augment_output_dir, embedding_models['minilm'], num_variations=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:53:59.491158Z",
     "iopub.status.busy": "2025-01-10T20:53:59.490840Z",
     "iopub.status.idle": "2025-01-10T20:55:37.272582Z",
     "shell.execute_reply": "2025-01-10T20:55:37.271793Z",
     "shell.execute_reply.started": "2025-01-10T20:53:59.491131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_augmented_train_set(original_embeddings, augmented_embeddings, num_augmentations):\n",
    "    new_train_embeddings = []\n",
    "    new_train_labels = []\n",
    "\n",
    "    for topic, orig_embed in original_embeddings.items():\n",
    "        new_train_embeddings.append(orig_embed)\n",
    "        new_train_labels += [topic] * len(orig_embed)\n",
    "\n",
    "        if topic in augmented_embeddings:\n",
    "            available_augmentations = len(augmented_embeddings[topic])\n",
    "            if available_augmentations < num_augmentations:\n",
    "                print(f\"âš ï¸ Warning: Not enough augmented embeddings for topic {topic}. Available: {available_augmentations}, Requested: {num_augmentations}\")\n",
    "                num_augmentations = available_augmentations\n",
    "\n",
    "            for i in range(num_augmentations):\n",
    "                new_train_embeddings.append(augmented_embeddings[topic][i])\n",
    "                new_train_labels.append(topic)\n",
    "\n",
    "    new_train_embeddings = np.vstack(new_train_embeddings)\n",
    "    new_train_labels = np.array(new_train_labels)\n",
    "\n",
    "    return new_train_embeddings, new_train_labels\n",
    "\n",
    "\n",
    "original_embeddings = {}\n",
    "augmented_embeddings = {}\n",
    "\n",
    "for topic in train_df['CategoryCode'].unique():\n",
    "    orig_file = os.path.join(\"embeddings/minilm/train\", f\"embeddings_{topic}.npy\")\n",
    "    original_embeddings[topic] = np.load(orig_file)\n",
    "\n",
    "    aug_file = os.path.join(\"augmented_data/minilm\", f\"embeddings_{topic}.npy\")\n",
    "    augmented_embeddings[topic] = np.load(aug_file)\n",
    "\n",
    "# EÄŸitim sÃ¼reci\n",
    "results_augmented = {size: [] for size in data_sizes}\n",
    "\n",
    "for size in data_sizes:\n",
    "    subset_embeddings = {}\n",
    "    for topic, embeddings in original_embeddings.items():\n",
    "        subset_embeddings[topic] = embeddings[:size // len(original_embeddings)]\n",
    "\n",
    "    for num_aug in [0, 1, 2, 4]:\n",
    "        print(f\"\\nData size: {size}, Augmentations per example: {num_aug}\")\n",
    "\n",
    "        train_embeddings, train_labels = create_augmented_train_set(\n",
    "            subset_embeddings, augmented_embeddings, num_aug\n",
    "        )\n",
    "\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            clf.fit(train_embeddings, train_labels)\n",
    "            predictions = clf.predict(test_embeddings)\n",
    "            accuracy = accuracy_score(test_labels, predictions)\n",
    "            f1 = f1_score(test_labels, predictions, average='weighted')\n",
    "\n",
    "            print(f\"ğŸ”„ {clf_name} - Accuracy={accuracy:.4f}, F1={f1:.4f}\")\n",
    "            results_augmented[size].append({\n",
    "                \"augmentations\": num_aug,\n",
    "                \"classifier\": clf_name,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"f1_score\": f1\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T21:08:14.843666Z",
     "iopub.status.busy": "2025-01-10T21:08:14.843288Z",
     "iopub.status.idle": "2025-01-10T21:08:15.231434Z",
     "shell.execute_reply": "2025-01-10T21:08:15.230552Z",
     "shell.execute_reply.started": "2025-01-10T21:08:14.843634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(results, metric=\"accuracy\"):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for clf_name in classifiers.keys():\n",
    "        for num_aug in [0, 1, 2, 4]:\n",
    "            metric_values = []\n",
    "            for size in data_sizes:\n",
    "                clf_results = [res for res in results[size] if res['classifier'] == clf_name and res['augmentations'] == num_aug]\n",
    "                if clf_results:\n",
    "                    metric_values.append(clf_results[0][metric])\n",
    "                else:\n",
    "                    metric_values.append(None)\n",
    "\n",
    "            plt.plot(data_sizes, metric_values, marker='o', label=f\"{clf_name} (Aug={num_aug})\")\n",
    "\n",
    "    plt.title(f\"Effect of Data Size and Augmentations on {metric.capitalize()}\")\n",
    "    plt.xlabel(\"Data Size\")\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.legend(title=\"Classifier and Augmentations\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(results_augmented, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6433546,
     "sourceId": 10385215,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
